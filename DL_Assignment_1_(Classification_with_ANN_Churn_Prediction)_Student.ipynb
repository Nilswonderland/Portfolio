{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nilswonderland/Portfolio/blob/main/DL_Assignment_1_(Classification_with_ANN_Churn_Prediction)_Student.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWwWowh5PtUj"
      },
      "source": [
        "___\n",
        "\n",
        "<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" alt=\"CLRSWY\"></p>\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeE-4CUGPtUm"
      },
      "source": [
        "<h1 style=\"text-align: center;\">Deep Learning<br><br>Assignment-1 (ANN)<br><br>Churn Prediction for Bank Customer<br><h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-TRnaDNPtUn"
      },
      "source": [
        "# Dataset Info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR_8anCJPtUo"
      },
      "source": [
        "We have a dataset in which there are details of a bank's customers and the target variable is a binary variable reflecting the fact whether the customer left the bank (closed his account) or he continues to be a customer.\n",
        "\n",
        "The features in the given dataset are:\n",
        "- **rownumber:** Row Numbers from 1 to 10000.\n",
        "- **customerid:** A unique ID that identifies each customer.\n",
        "- **surname:** The customer’s surname.\n",
        "- **creditscore:** A credit score is a number between 300–850 that depicts a consumer's creditworthiness.\n",
        "- **geography:** The country from which the customer belongs to.\n",
        "- **Gender:** The customer’s gender: Male, Female\n",
        "- **Age:** The customer’s current age, in years, at the time of being customer.\n",
        "- **tenure:** The number of years for which the customer has been with the bank.\n",
        "- **balance:** Bank balance of the customer.\n",
        "- **numofproducts:** the number of bank products the customer is utilising.\n",
        "- **hascrcard:** The number of credit cards given to the customer by the bank.\n",
        "- **isactivemember:** Binary Flag for indicating if the client is active or not with the bank before the moment where the client exits the company (recorded in the variable \"exited\")\n",
        "- **exited:** Binary flag 1 if the customer closed account with bank and 0 if the customer is retained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzySe_DqPtUp"
      },
      "source": [
        "# Import Libraries & Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd      \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from yellowbrick.classifier import PrecisionRecallCurve\n",
        "\n",
        "from scipy.stats import skew\n",
        "from scipy.cluster.hierarchy import linkage\n",
        "\n",
        "from sklearn.model_selection import cross_validate, cross_val_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import classification_report,confusion_matrix,plot_confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.cluster import KMeans\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "from yellowbrick.cluster import SilhouetteVisualizer\n",
        "\n",
        "\n",
        "pd.set_option('display.max_rows', 1000)\n",
        "pd.set_option('display.max_columns', 1000)\n",
        "pd.set_option('display.width', 1000)"
      ],
      "metadata": {
        "id": "MKNjy0BGQBnq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "VwSYy4BkPtUq",
        "outputId": "27fa1001-72d2-41a1-e89a-83399c530505"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  Exited\n",
              "0          1    15634602  Hargrave          619    France  Female   42       2       0.00              1          1               1        101348.88       1\n",
              "1          2    15647311      Hill          608     Spain  Female   41       1   83807.86              1          0               1        112542.58       0\n",
              "2          3    15619304      Onio          502    France  Female   42       8  159660.80              3          1               0        113931.57       1\n",
              "3          4    15701354      Boni          699    France  Female   39       1       0.00              2          0               0         93826.63       0\n",
              "4          5    15737888  Mitchell          850     Spain  Female   43       2  125510.82              1          1               1         79084.10       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3b47cd8e-aec0-4164-a05d-1bd3839b7cc9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b47cd8e-aec0-4164-a05d-1bd3839b7cc9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3b47cd8e-aec0-4164-a05d-1bd3839b7cc9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3b47cd8e-aec0-4164-a05d-1bd3839b7cc9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df= pd.read_csv('Churn_Modelling.csv')\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "et-eAGSnPtUr",
        "outputId": "e27061b8-ed92-4c83-aea8-5df4e9106ed1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   RowNumber        10000 non-null  int64  \n",
            " 1   CustomerId       10000 non-null  int64  \n",
            " 2   Surname          10000 non-null  object \n",
            " 3   CreditScore      10000 non-null  int64  \n",
            " 4   Geography        10000 non-null  object \n",
            " 5   Gender           10000 non-null  object \n",
            " 6   Age              10000 non-null  int64  \n",
            " 7   Tenure           10000 non-null  int64  \n",
            " 8   Balance          10000 non-null  float64\n",
            " 9   NumOfProducts    10000 non-null  int64  \n",
            " 10  HasCrCard        10000 non-null  int64  \n",
            " 11  IsActiveMember   10000 non-null  int64  \n",
            " 12  EstimatedSalary  10000 non-null  float64\n",
            " 13  Exited           10000 non-null  int64  \n",
            "dtypes: float64(2), int64(9), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "1ydJbKj6Q9BQ",
        "outputId": "43b42bc3-452a-4a25-9ffe-67c750c634b5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   count          mean           std          min          25%           50%           75%          max\n",
              "RowNumber        10000.0  5.000500e+03   2886.895680         1.00      2500.75  5.000500e+03  7.500250e+03     10000.00\n",
              "CustomerId       10000.0  1.569094e+07  71936.186123  15565701.00  15628528.25  1.569074e+07  1.575323e+07  15815690.00\n",
              "CreditScore      10000.0  6.505288e+02     96.653299       350.00       584.00  6.520000e+02  7.180000e+02       850.00\n",
              "Age              10000.0  3.892180e+01     10.487806        18.00        32.00  3.700000e+01  4.400000e+01        92.00\n",
              "Tenure           10000.0  5.012800e+00      2.892174         0.00         3.00  5.000000e+00  7.000000e+00        10.00\n",
              "Balance          10000.0  7.648589e+04  62397.405202         0.00         0.00  9.719854e+04  1.276442e+05    250898.09\n",
              "NumOfProducts    10000.0  1.530200e+00      0.581654         1.00         1.00  1.000000e+00  2.000000e+00         4.00\n",
              "HasCrCard        10000.0  7.055000e-01      0.455840         0.00         0.00  1.000000e+00  1.000000e+00         1.00\n",
              "IsActiveMember   10000.0  5.151000e-01      0.499797         0.00         0.00  1.000000e+00  1.000000e+00         1.00\n",
              "EstimatedSalary  10000.0  1.000902e+05  57510.492818        11.58     51002.11  1.001939e+05  1.493882e+05    199992.48\n",
              "Exited           10000.0  2.037000e-01      0.402769         0.00         0.00  0.000000e+00  0.000000e+00         1.00"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28720e16-45af-4857-9eee-3b30bbdb046e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>RowNumber</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>5.000500e+03</td>\n",
              "      <td>2886.895680</td>\n",
              "      <td>1.00</td>\n",
              "      <td>2500.75</td>\n",
              "      <td>5.000500e+03</td>\n",
              "      <td>7.500250e+03</td>\n",
              "      <td>10000.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CustomerId</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>1.569094e+07</td>\n",
              "      <td>71936.186123</td>\n",
              "      <td>15565701.00</td>\n",
              "      <td>15628528.25</td>\n",
              "      <td>1.569074e+07</td>\n",
              "      <td>1.575323e+07</td>\n",
              "      <td>15815690.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CreditScore</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>6.505288e+02</td>\n",
              "      <td>96.653299</td>\n",
              "      <td>350.00</td>\n",
              "      <td>584.00</td>\n",
              "      <td>6.520000e+02</td>\n",
              "      <td>7.180000e+02</td>\n",
              "      <td>850.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>3.892180e+01</td>\n",
              "      <td>10.487806</td>\n",
              "      <td>18.00</td>\n",
              "      <td>32.00</td>\n",
              "      <td>3.700000e+01</td>\n",
              "      <td>4.400000e+01</td>\n",
              "      <td>92.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tenure</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>5.012800e+00</td>\n",
              "      <td>2.892174</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.00</td>\n",
              "      <td>5.000000e+00</td>\n",
              "      <td>7.000000e+00</td>\n",
              "      <td>10.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Balance</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>7.648589e+04</td>\n",
              "      <td>62397.405202</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>9.719854e+04</td>\n",
              "      <td>1.276442e+05</td>\n",
              "      <td>250898.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumOfProducts</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>1.530200e+00</td>\n",
              "      <td>0.581654</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>4.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HasCrCard</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>7.055000e-01</td>\n",
              "      <td>0.455840</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IsActiveMember</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>5.151000e-01</td>\n",
              "      <td>0.499797</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>1.000902e+05</td>\n",
              "      <td>57510.492818</td>\n",
              "      <td>11.58</td>\n",
              "      <td>51002.11</td>\n",
              "      <td>1.001939e+05</td>\n",
              "      <td>1.493882e+05</td>\n",
              "      <td>199992.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Exited</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>2.037000e-01</td>\n",
              "      <td>0.402769</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28720e16-45af-4857-9eee-3b30bbdb046e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-28720e16-45af-4857-9eee-3b30bbdb046e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-28720e16-45af-4857-9eee-3b30bbdb046e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "El9mZvr-RE6H",
        "outputId": "3a9863c8-2f61-4a20-c0b2-e652642f2698"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V--SZyi7RLwI",
        "outputId": "3e5fdc05-affe-4044-eda7-f128cf048df1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RowNumber          10000\n",
              "CustomerId         10000\n",
              "Surname             2932\n",
              "CreditScore          460\n",
              "Geography              3\n",
              "Gender                 2\n",
              "Age                   70\n",
              "Tenure                11\n",
              "Balance             6382\n",
              "NumOfProducts          4\n",
              "HasCrCard              2\n",
              "IsActiveMember         2\n",
              "EstimatedSalary     9999\n",
              "Exited                 2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoNPntvsRWQM",
        "outputId": "1f43e337-77a4-41b1-a00b-d9a53c923c1a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RowNumber          0\n",
              "CustomerId         0\n",
              "Surname            0\n",
              "CreditScore        0\n",
              "Geography          0\n",
              "Gender             0\n",
              "Age                0\n",
              "Tenure             0\n",
              "Balance            0\n",
              "NumOfProducts      0\n",
              "HasCrCard          0\n",
              "IsActiveMember     0\n",
              "EstimatedSalary    0\n",
              "Exited             0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRkI31hYPtUs"
      },
      "source": [
        "# Exploratory Data Analysis and Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TRcBwZ-PtUs"
      },
      "source": [
        "1. Implement basic steps to see how is your data looks like\n",
        "2. Check for missing values\n",
        "3. Drop the features that not suitable for modelling\n",
        "4. Implement basic visualization steps such as histogram, countplot, heatmap\n",
        "5. Convert categorical variables to dummy variables"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns= \"RowNumber\", inplace=True)"
      ],
      "metadata": {
        "id": "voO9k7uDSm8L"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns= \"Surname\", inplace=True)"
      ],
      "metadata": {
        "id": "q4tjF4L6S5eK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "ax=sns.countplot(x ='Age', data = df)\n",
        "plt.title('Age Distribution')\n",
        "plt.xlabel('Age')\n",
        "plt.show();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "-iufM8UFTB7u",
        "outputId": "7fe118e6-6586-4ee5-9578-7d29f2c6fd05"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "swVOrVvoPtUu",
        "outputId": "e5eccb69-3860-405f-d004-d469aea64020"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      CustomerId  CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  Exited  Geography_Germany  Geography_Spain  Gender_Male\n",
              "0       15634602          619   42       2       0.00              1          1               1        101348.88       1                  0                0            0\n",
              "1       15647311          608   41       1   83807.86              1          0               1        112542.58       0                  0                1            0\n",
              "2       15619304          502   42       8  159660.80              3          1               0        113931.57       1                  0                0            0\n",
              "3       15701354          699   39       1       0.00              2          0               0         93826.63       0                  0                0            0\n",
              "4       15737888          850   43       2  125510.82              1          1               1         79084.10       0                  0                1            0\n",
              "...          ...          ...  ...     ...        ...            ...        ...             ...              ...     ...                ...              ...          ...\n",
              "9995    15606229          771   39       5       0.00              2          1               0         96270.64       0                  0                0            1\n",
              "9996    15569892          516   35      10   57369.61              1          1               1        101699.77       0                  0                0            1\n",
              "9997    15584532          709   36       7       0.00              1          0               1         42085.58       1                  0                0            0\n",
              "9998    15682355          772   42       3   75075.31              2          1               0         92888.52       1                  1                0            1\n",
              "9999    15628319          792   28       4  130142.79              1          1               0         38190.78       0                  0                0            0\n",
              "\n",
              "[10000 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8de53cf4-4b2d-4eb9-9fd5-ab35e70d56c4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "      <th>Geography_Germany</th>\n",
              "      <th>Geography_Spain</th>\n",
              "      <th>Gender_Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15634602</td>\n",
              "      <td>619</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15647311</td>\n",
              "      <td>608</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15619304</td>\n",
              "      <td>502</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15701354</td>\n",
              "      <td>699</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15737888</td>\n",
              "      <td>850</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>15606229</td>\n",
              "      <td>771</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270.64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>15569892</td>\n",
              "      <td>516</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699.77</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>15584532</td>\n",
              "      <td>709</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085.58</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>15682355</td>\n",
              "      <td>772</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075.31</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888.52</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>15628319</td>\n",
              "      <td>792</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142.79</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190.78</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8de53cf4-4b2d-4eb9-9fd5-ab35e70d56c4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8de53cf4-4b2d-4eb9-9fd5-ab35e70d56c4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8de53cf4-4b2d-4eb9-9fd5-ab35e70d56c4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "df=pd.get_dummies(df,drop_first=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOcX3nvkPtUt"
      },
      "source": [
        "# Preprocessing of Data\n",
        "- Train | Test Split, Scalling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.drop([\"Exited\"], axis=1)\n",
        "y=df[\"Exited\"]"
      ],
      "metadata": {
        "id": "LOvfcD4_UhbK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,stratify=y, random_state=5)"
      ],
      "metadata": {
        "id": "OeNfTP2JUtJZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler= MinMaxScaler() "
      ],
      "metadata": {
        "id": "yBS9JNImUt7a"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled = scaler.fit_transform(X_train)"
      ],
      "metadata": {
        "id": "6mnh4wu_UxfQ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Ofa_JuXfUz_b"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha9hDt_AoGaE"
      },
      "source": [
        "# Modelling & Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_model = LogisticRegression()"
      ],
      "metadata": {
        "id": "hrsHvjEnVF4p"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_model.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dJCLtgTVKcf",
        "outputId": "93b50c68-3d32-41af-c2fe-d7552d64b702"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=log_model.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "_1wlS8hGVS1t"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_proba = log_model.predict_proba(X_test_scaled)"
      ],
      "metadata": {
        "id": "uFj-PgP3VVF6"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_metric(model, X_train, y_train, X_test, y_test):\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    \n",
        "    print(\"Test_Set\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print()\n",
        "    print(\"Train_Set\")\n",
        "    print(confusion_matrix(y_train, y_train_pred))\n",
        "    print(classification_report(y_train, y_train_pred))"
      ],
      "metadata": {
        "id": "NYn9glaWVaSN"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_metric(log_model, X_train_scaled, y_train, X_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bh28U3pXVdes",
        "outputId": "2ddcd69b-db31-4aea-a86c-55b14f3074b5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test_Set\n",
            "[[1542   51]\n",
            " [ 325   82]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.97      0.89      1593\n",
            "           1       0.62      0.20      0.30       407\n",
            "\n",
            "    accuracy                           0.81      2000\n",
            "   macro avg       0.72      0.58      0.60      2000\n",
            "weighted avg       0.78      0.81      0.77      2000\n",
            "\n",
            "\n",
            "Train_Set\n",
            "[[6178  192]\n",
            " [1309  321]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.97      0.89      6370\n",
            "           1       0.63      0.20      0.30      1630\n",
            "\n",
            "    accuracy                           0.81      8000\n",
            "   macro avg       0.73      0.58      0.60      8000\n",
            "weighted avg       0.78      0.81      0.77      8000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression()\n",
        "scores = cross_validate(model, X_train_scaled, y_train, scoring = ['precision','recall','f1','accuracy'], cv = 10)\n",
        "df_scores = pd.DataFrame(scores, index = range(1, 11))\n",
        "df_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "CynJI1C9Vi9-",
        "outputId": "568945d8-7322-4280-9b54-e7b1d5de001a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    fit_time  score_time  test_precision  test_recall   test_f1  test_accuracy\n",
              "1   0.132810    0.013798        0.688889     0.190184  0.298077        0.81750\n",
              "2   0.108535    0.010989        0.625000     0.184049  0.284360        0.81125\n",
              "3   0.100682    0.014422        0.575000     0.141104  0.226601        0.80375\n",
              "4   0.126092    0.015439        0.522727     0.141104  0.222222        0.79875\n",
              "5   0.097282    0.014180        0.616667     0.226994  0.331839        0.81375\n",
              "6   0.137220    0.019230        0.596491     0.208589  0.309091        0.81000\n",
              "7   0.193739    0.013102        0.610169     0.220859  0.324324        0.81250\n",
              "8   0.166904    0.014873        0.611111     0.202454  0.304147        0.81125\n",
              "9   0.163291    0.015754        0.745098     0.233129  0.355140        0.82750\n",
              "10  0.131662    0.014975        0.518519     0.171779  0.258065        0.79875"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-007fe006-ad51-4226-85b2-92ea1d761260\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>test_precision</th>\n",
              "      <th>test_recall</th>\n",
              "      <th>test_f1</th>\n",
              "      <th>test_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.132810</td>\n",
              "      <td>0.013798</td>\n",
              "      <td>0.688889</td>\n",
              "      <td>0.190184</td>\n",
              "      <td>0.298077</td>\n",
              "      <td>0.81750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.108535</td>\n",
              "      <td>0.010989</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.184049</td>\n",
              "      <td>0.284360</td>\n",
              "      <td>0.81125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.100682</td>\n",
              "      <td>0.014422</td>\n",
              "      <td>0.575000</td>\n",
              "      <td>0.141104</td>\n",
              "      <td>0.226601</td>\n",
              "      <td>0.80375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.126092</td>\n",
              "      <td>0.015439</td>\n",
              "      <td>0.522727</td>\n",
              "      <td>0.141104</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.79875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.097282</td>\n",
              "      <td>0.014180</td>\n",
              "      <td>0.616667</td>\n",
              "      <td>0.226994</td>\n",
              "      <td>0.331839</td>\n",
              "      <td>0.81375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.137220</td>\n",
              "      <td>0.019230</td>\n",
              "      <td>0.596491</td>\n",
              "      <td>0.208589</td>\n",
              "      <td>0.309091</td>\n",
              "      <td>0.81000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.193739</td>\n",
              "      <td>0.013102</td>\n",
              "      <td>0.610169</td>\n",
              "      <td>0.220859</td>\n",
              "      <td>0.324324</td>\n",
              "      <td>0.81250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.166904</td>\n",
              "      <td>0.014873</td>\n",
              "      <td>0.611111</td>\n",
              "      <td>0.202454</td>\n",
              "      <td>0.304147</td>\n",
              "      <td>0.81125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.163291</td>\n",
              "      <td>0.015754</td>\n",
              "      <td>0.745098</td>\n",
              "      <td>0.233129</td>\n",
              "      <td>0.355140</td>\n",
              "      <td>0.82750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.131662</td>\n",
              "      <td>0.014975</td>\n",
              "      <td>0.518519</td>\n",
              "      <td>0.171779</td>\n",
              "      <td>0.258065</td>\n",
              "      <td>0.79875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-007fe006-ad51-4226-85b2-92ea1d761260')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-007fe006-ad51-4226-85b2-92ea1d761260 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-007fe006-ad51-4226-85b2-92ea1d761260');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_scores.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy0JOfQeVuLS",
        "outputId": "ff06b7f2-25a3-4288-bccd-fec8f6fb1d1f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fit_time          0.135822\n",
              "score_time        0.014676\n",
              "test_precision    0.610967\n",
              "test_recall       0.192025\n",
              "test_f1           0.291387\n",
              "test_accuracy     0.810500\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import plot_roc_curve, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "RVEqMVflYUxW"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3CWQTJzYY4x",
        "outputId": "279bfc1d-5a65-492b-ec21-03fb9231e5f8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzyJhJnpPtUv"
      },
      "source": [
        "## without class_weigth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ikp7ijdCPtUw"
      },
      "source": [
        "### Create The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dW3aROWTPtUx"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Yl98Q8NPtUx"
      },
      "source": [
        "### Evaluate The Model\n",
        "\n",
        "- Plot the model history to observe the changing of metrics\n",
        "- Make prediction to see \"confusion matrix\" and \"classification report\"\n",
        "- Check ROC (Receiver Operating Curve) and AUC (Area Under Curve) for the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NAxbK-uPtUy"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6_Pq25mPtUz"
      },
      "source": [
        "## with class_weigth\n",
        "\n",
        "Investigate how the \"class_weight\" hyper-parameter is used in a Neural Network."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import class_weight\n",
        "\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                  classes=np.unique(y_train),\n",
        "                                                  y=y_train)\n",
        "\n",
        "class_weights = {0: class_weights[0], 1: class_weights[1]}\n",
        "class_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9O2XThbPWRhL",
        "outputId": "cd18ec25-55b7-456d-c1b7-df8e1b7a0e4b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.6279434850863422, 1: 2.4539877300613497}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuBIGY-gPtUz"
      },
      "source": [
        "### Create The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "DoohSAZqPtU0"
      },
      "outputs": [],
      "source": [
        "seed= 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPmQ1NsYPtU0"
      },
      "source": [
        "### Evaluate The Model\n",
        "\n",
        "- Plot the model history to observe the changing of metrics\n",
        "- Make prediction to see \"confusion matrix\" and \"classification report\"\n",
        "- Check ROC (Receiver Operating Curve) and AUC (Area Under Curve) for the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIvwa49XPtU0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esUs1dNXPtU1"
      },
      "source": [
        "## Implementation Different Methods to Develop The Model\n",
        "\n",
        "- Implement the following methods on model creating with \"class_weight\" parameter\n",
        "- Create and evaluate model for each method "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBjKNpTKPtU1"
      },
      "source": [
        "### Increase The Learning Rate and Observe The Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LLHDBErPtU1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ztU1vPJPtU2"
      },
      "source": [
        "### Add Dropout Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "kazZ1jfHPtU3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(seed)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(36, activation=\"relu\", input_dim = X_train.shape[1]))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(18, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(9, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "opt = Adam(lr = 0.001)\n",
        "model.compile(optimizer = opt, loss = \"binary_crossentropy\", metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "mAi45Q8mb6pN"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x = X_train, y = y_train, validation_split = 0.1, batch_size = 32, epochs = 1000, verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYjRR23zcHyq",
        "outputId": "3fc53082-a88f-4231-8f37-021e346cf205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "225/225 [==============================] - 3s 7ms/step - loss: 154812.3438 - accuracy: 0.6808 - val_loss: 8.7589 - val_accuracy: 0.8062\n",
            "Epoch 2/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 18917.6445 - accuracy: 0.7414 - val_loss: 0.6021 - val_accuracy: 0.8062\n",
            "Epoch 3/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 5956.6182 - accuracy: 0.7547 - val_loss: 0.5662 - val_accuracy: 0.8062\n",
            "Epoch 4/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 2491.5962 - accuracy: 0.7613 - val_loss: 0.5417 - val_accuracy: 0.8062\n",
            "Epoch 5/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 1461.7301 - accuracy: 0.7629 - val_loss: 0.5245 - val_accuracy: 0.8062\n",
            "Epoch 6/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 1209.8535 - accuracy: 0.7725 - val_loss: 0.5150 - val_accuracy: 0.8062\n",
            "Epoch 7/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 551.4219 - accuracy: 0.7749 - val_loss: 0.5069 - val_accuracy: 0.8062\n",
            "Epoch 8/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 487.1354 - accuracy: 0.7753 - val_loss: 0.5016 - val_accuracy: 0.8062\n",
            "Epoch 9/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 295.3297 - accuracy: 0.7794 - val_loss: 0.4981 - val_accuracy: 0.8062\n",
            "Epoch 10/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 268.4896 - accuracy: 0.7804 - val_loss: 0.4958 - val_accuracy: 0.8062\n",
            "Epoch 11/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 181.6725 - accuracy: 0.7754 - val_loss: 0.4942 - val_accuracy: 0.8062\n",
            "Epoch 12/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 212.8212 - accuracy: 0.7811 - val_loss: 0.4934 - val_accuracy: 0.8062\n",
            "Epoch 13/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 216.1551 - accuracy: 0.7757 - val_loss: 0.4928 - val_accuracy: 0.8062\n",
            "Epoch 14/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 75.9762 - accuracy: 0.7818 - val_loss: 0.4925 - val_accuracy: 0.8062\n",
            "Epoch 15/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 102.6325 - accuracy: 0.7803 - val_loss: 0.4923 - val_accuracy: 0.8062\n",
            "Epoch 16/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 156.2771 - accuracy: 0.7819 - val_loss: 0.4923 - val_accuracy: 0.8062\n",
            "Epoch 17/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 14.6462 - accuracy: 0.7832 - val_loss: 0.4923 - val_accuracy: 0.8062\n",
            "Epoch 18/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 66.1728 - accuracy: 0.7832 - val_loss: 0.4922 - val_accuracy: 0.8062\n",
            "Epoch 19/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 71.3405 - accuracy: 0.7839 - val_loss: 0.4922 - val_accuracy: 0.8062\n",
            "Epoch 20/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 41.0794 - accuracy: 0.7843 - val_loss: 0.4921 - val_accuracy: 0.8062\n",
            "Epoch 21/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 72.4638 - accuracy: 0.7876 - val_loss: 0.4921 - val_accuracy: 0.8062\n",
            "Epoch 22/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 33.7575 - accuracy: 0.7899 - val_loss: 0.4922 - val_accuracy: 0.8062\n",
            "Epoch 23/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 31.4958 - accuracy: 0.7925 - val_loss: 0.4921 - val_accuracy: 0.8062\n",
            "Epoch 24/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 20.6347 - accuracy: 0.7911 - val_loss: 0.4921 - val_accuracy: 0.8062\n",
            "Epoch 25/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 13.8396 - accuracy: 0.7918 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 26/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 36.3016 - accuracy: 0.7912 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 27/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 13.9974 - accuracy: 0.7915 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 28/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 13.9812 - accuracy: 0.7929 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 29/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 13.9325 - accuracy: 0.7926 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 30/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 13.3523 - accuracy: 0.7932 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 31/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 7.8400 - accuracy: 0.7924 - val_loss: 0.4919 - val_accuracy: 0.8062\n",
            "Epoch 32/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 6.4784 - accuracy: 0.7939 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 33/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 27.8982 - accuracy: 0.7924 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 34/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 10.5979 - accuracy: 0.7928 - val_loss: 0.4921 - val_accuracy: 0.8062\n",
            "Epoch 35/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 10.3535 - accuracy: 0.7922 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 36/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 5.4566 - accuracy: 0.7935 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 37/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 2.7727 - accuracy: 0.7939 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 38/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 1.7756 - accuracy: 0.7942 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 39/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 10.1661 - accuracy: 0.7947 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 40/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 1.1636 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.8062\n",
            "Epoch 41/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 5.1105 - accuracy: 0.7949 - val_loss: 0.4921 - val_accuracy: 0.8062\n",
            "Epoch 42/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 2.6583 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.8062\n",
            "Epoch 43/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 4.9148 - accuracy: 0.7949 - val_loss: 0.4921 - val_accuracy: 0.8062\n",
            "Epoch 44/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 3.6228 - accuracy: 0.7953 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 45/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 1.2820 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 46/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 1.5152 - accuracy: 0.7947 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 47/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 4.9450 - accuracy: 0.7947 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 48/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.7445 - accuracy: 0.7947 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 49/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 1.0126 - accuracy: 0.7946 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 50/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5067 - accuracy: 0.7953 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 51/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6126 - accuracy: 0.7950 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 52/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5068 - accuracy: 0.7953 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 53/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5070 - accuracy: 0.7951 - val_loss: 0.4919 - val_accuracy: 0.8062\n",
            "Epoch 54/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.9302 - accuracy: 0.7949 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 55/1000\n",
            "225/225 [==============================] - 2s 9ms/step - loss: 0.6836 - accuracy: 0.7950 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 56/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 1.7762 - accuracy: 0.7949 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 57/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.6639 - accuracy: 0.7950 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 58/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 1.6881 - accuracy: 0.7950 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 59/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5490 - accuracy: 0.7950 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 60/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5238 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 61/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5823 - accuracy: 0.7953 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 62/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.9618 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 63/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 64/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 1.0131 - accuracy: 0.7950 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 65/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 1.0567 - accuracy: 0.7949 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 66/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5067 - accuracy: 0.7954 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 67/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 2.1854 - accuracy: 0.7949 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 68/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 1.3351 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 69/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 70/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 71/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 72/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5069 - accuracy: 0.7953 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 73/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6308 - accuracy: 0.7950 - val_loss: 0.4919 - val_accuracy: 0.8062\n",
            "Epoch 74/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6117 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 75/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6324 - accuracy: 0.7950 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 76/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 77/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5070 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 78/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 79/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 80/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 81/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 82/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 83/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 84/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 85/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 86/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5690 - accuracy: 0.7950 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 87/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4919 - val_accuracy: 0.8062\n",
            "Epoch 88/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5069 - accuracy: 0.7953 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 89/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 90/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6311 - accuracy: 0.7950 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 91/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4919 - val_accuracy: 0.8062\n",
            "Epoch 92/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5231 - accuracy: 0.7950 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 93/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 94/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 95/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.8062\n",
            "Epoch 96/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 97/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5069 - accuracy: 0.7953 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 98/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5069 - accuracy: 0.7953 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 99/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 100/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6379 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 101/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 102/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 103/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 104/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 2.3407 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 105/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 106/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 1.3036 - accuracy: 0.7949 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 107/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 108/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 109/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 110/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6812 - accuracy: 0.7950 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 111/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 112/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 113/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 114/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5069 - accuracy: 0.7953 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 115/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 116/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 117/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 118/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 119/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6206 - accuracy: 0.7950 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 120/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 121/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 122/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 123/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.8062\n",
            "Epoch 124/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 125/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 126/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 127/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5441 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 128/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 129/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 130/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5070 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 131/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 132/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 133/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 134/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 135/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.8062\n",
            "Epoch 136/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 137/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6467 - accuracy: 0.7950 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 138/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 139/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 140/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6053 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 141/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 142/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 143/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 144/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 145/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 146/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 147/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 148/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5335 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 149/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 150/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 151/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 152/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 153/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 154/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 155/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 156/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 157/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 158/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 159/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 160/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5164 - accuracy: 0.7950 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 161/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 162/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 163/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 164/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 165/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5344 - accuracy: 0.7950 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 166/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 167/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 168/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 169/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 170/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 171/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 172/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 173/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 174/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 175/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5069 - accuracy: 0.7953 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 176/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 177/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 178/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 179/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 180/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 181/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 182/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 183/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 184/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 185/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6255 - accuracy: 0.7950 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 186/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.8062\n",
            "Epoch 187/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 188/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 189/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 190/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 191/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 192/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 193/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4919 - val_accuracy: 0.8062\n",
            "Epoch 194/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 195/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 196/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 197/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 198/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 199/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 200/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 201/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 202/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 203/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 204/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 205/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 206/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 207/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 208/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 209/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 210/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 211/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 212/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 213/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 214/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 215/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 216/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 217/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 218/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 219/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 220/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 221/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 222/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 223/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 224/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 225/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 226/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 227/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 228/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 229/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 230/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 231/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 232/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 233/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 234/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 235/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 236/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 237/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 238/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 239/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 240/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 241/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 242/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 243/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 244/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 245/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 246/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 247/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 248/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 249/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 250/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 251/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 252/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 253/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 254/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 255/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 256/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 257/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 258/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 259/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 260/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 261/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 262/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 263/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 264/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 265/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 266/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4919 - val_accuracy: 0.8062\n",
            "Epoch 267/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 268/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 269/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 270/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 271/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 272/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 273/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 274/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 275/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 276/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 277/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4919 - val_accuracy: 0.8062\n",
            "Epoch 278/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 279/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 280/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 281/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 282/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 283/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 284/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 285/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 286/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 287/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 288/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 289/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 290/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 291/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 292/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 293/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 294/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 295/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 296/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 297/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 298/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4919 - val_accuracy: 0.8062\n",
            "Epoch 299/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 300/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 301/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 302/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 303/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 304/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 305/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 306/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 307/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 308/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 309/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 310/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 311/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 312/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 313/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4919 - val_accuracy: 0.8062\n",
            "Epoch 314/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 315/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 316/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 317/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 318/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 319/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 320/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 321/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 322/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.8062\n",
            "Epoch 323/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 324/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 325/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 326/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 327/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 328/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 329/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 330/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 331/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 332/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 333/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 334/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 335/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 336/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 337/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 338/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 339/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 340/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 341/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 342/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 343/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 344/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 345/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 346/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 347/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 348/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 349/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 350/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 351/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.8062\n",
            "Epoch 352/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 353/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 354/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 355/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 356/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 357/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 358/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 359/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 360/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 361/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 362/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 363/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 364/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 365/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 366/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 367/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 368/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 369/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 370/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 371/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 372/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 373/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 374/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 375/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 376/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 377/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 378/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 379/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 380/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 381/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 382/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 383/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 384/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 385/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 386/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 387/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4919 - val_accuracy: 0.8062\n",
            "Epoch 388/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 389/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 390/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 391/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 392/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 393/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 394/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 395/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 396/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 397/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 398/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 399/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 400/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 401/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 402/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 403/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 404/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.8062\n",
            "Epoch 405/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 406/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 407/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 408/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 409/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 410/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 411/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 412/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 413/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 414/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 415/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4919 - val_accuracy: 0.8062\n",
            "Epoch 416/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 417/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 418/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 419/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 420/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 421/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 422/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 423/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 424/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 425/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 426/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 427/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 428/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 429/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 430/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 431/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 432/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 433/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 434/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4919 - val_accuracy: 0.8062\n",
            "Epoch 435/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 436/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 437/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 438/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 439/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 440/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 441/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4919 - val_accuracy: 0.8062\n",
            "Epoch 442/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 443/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 444/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 445/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 446/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 447/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 448/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 449/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 450/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 451/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 452/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 453/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 454/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 455/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 456/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 457/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 458/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 459/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 460/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 461/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 462/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 463/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 464/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 465/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 466/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 467/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 468/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 469/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 470/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 471/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 472/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 473/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 474/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4919 - val_accuracy: 0.8062\n",
            "Epoch 475/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 476/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 477/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 478/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 479/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 480/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 481/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 482/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 483/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 484/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 485/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 486/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 487/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 488/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 489/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 490/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 491/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 492/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 493/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 494/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 495/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 496/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 497/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 498/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 499/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 500/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 501/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 502/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 503/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 504/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 505/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 506/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 507/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 508/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 509/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 510/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 511/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 512/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 513/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 514/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 515/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.8062\n",
            "Epoch 516/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 517/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 518/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 519/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4919 - val_accuracy: 0.8062\n",
            "Epoch 520/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 521/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 522/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 523/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 524/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 525/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 526/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 527/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.8062\n",
            "Epoch 528/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.8062\n",
            "Epoch 529/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 530/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 531/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 532/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 533/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 534/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 535/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 536/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 537/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 538/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 539/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 540/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 541/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 542/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 543/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 544/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 545/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 546/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 547/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 548/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 549/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 550/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 551/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 552/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 553/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 554/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 555/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 556/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 557/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 558/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 559/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 560/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 561/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 562/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 563/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 564/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 565/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 566/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 567/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 568/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 569/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 570/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 571/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 572/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 573/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 574/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 575/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 576/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 577/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 578/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 579/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 580/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 581/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 582/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 583/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 584/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 585/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 586/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 587/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 588/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 589/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 590/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 591/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 592/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 593/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 594/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4919 - val_accuracy: 0.8062\n",
            "Epoch 595/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4919 - val_accuracy: 0.8062\n",
            "Epoch 596/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 597/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 598/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 599/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 600/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 601/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 602/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 603/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 604/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 605/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 606/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 607/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.8062\n",
            "Epoch 608/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.8062\n",
            "Epoch 609/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 610/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 611/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 612/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 613/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 614/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 615/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 616/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 617/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 618/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 619/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 620/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 621/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 622/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 623/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 624/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 625/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 626/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 627/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 628/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 629/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 630/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 631/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 632/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 633/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 634/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 635/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 636/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 637/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 638/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.8062\n",
            "Epoch 639/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 640/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 641/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 642/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 643/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 644/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 645/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 646/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 647/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 648/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.8062\n",
            "Epoch 649/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.8062\n",
            "Epoch 650/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 651/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 652/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 653/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 654/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 655/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 656/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4919 - val_accuracy: 0.8062\n",
            "Epoch 657/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 658/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 659/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 660/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 661/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.8062\n",
            "Epoch 662/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 663/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 664/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 665/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 666/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 667/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 668/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 669/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 670/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 671/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 672/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 673/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 674/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 675/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 676/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 677/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.8062\n",
            "Epoch 678/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 679/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 680/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 681/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 682/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.8062\n",
            "Epoch 683/1000\n",
            " 52/225 [=====>........................] - ETA: 0s - loss: 0.5275 - accuracy: 0.7800"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_df = pd.DataFrame(model.history.history)\n",
        "loss_df.plot()"
      ],
      "metadata": {
        "id": "5XfVIJQWcM2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"loss : \", loss)\n",
        "print(\"accuracy : \", accuracy)"
      ],
      "metadata": {
        "id": "f-2EN41LcSrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "J0Jp4TuBcTTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Je43QmgKPtU3"
      },
      "source": [
        "### Add Early Stop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42"
      ],
      "metadata": {
        "id": "3FG2LFirZYd2"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "OoRdoKyPY37g"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(seed)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(36, activation = \"relu\", input_dim = X_train.shape[1]))\n",
        "model.add(Dense(18, activation = \"relu\"))\n",
        "model.add(Dense(9, activation = \"relu\"))\n",
        "model.add(Dense(1, activation = \"sigmoid\"))\n",
        "\n",
        "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "A66HESBjY6g9"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", verbose = 1, patience = 15, restore_best_weights = True)"
      ],
      "metadata": {
        "id": "97aK1Y8NZBJ4"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x = X_train, y = y_train, validation_split = 0.1, batch_size = 32, epochs = 1000, verbose = 1,\n",
        "          callbacks = [early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-1ge6vNZEGd",
        "outputId": "7e7b1005-3480-4b2a-f486-8307f4630999"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "225/225 [==============================] - 2s 4ms/step - loss: 4729.2300 - accuracy: 0.6719 - val_loss: 1567.5164 - val_accuracy: 0.8050\n",
            "Epoch 2/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 2560.3813 - accuracy: 0.6744 - val_loss: 1546.5757 - val_accuracy: 0.8062\n",
            "Epoch 3/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 3884.7693 - accuracy: 0.6771 - val_loss: 2230.1482 - val_accuracy: 0.1937\n",
            "Epoch 4/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 3051.7058 - accuracy: 0.6765 - val_loss: 1676.5920 - val_accuracy: 0.8062\n",
            "Epoch 5/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 2355.6067 - accuracy: 0.6783 - val_loss: 316.6895 - val_accuracy: 0.5688\n",
            "Epoch 6/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 2097.3716 - accuracy: 0.6789 - val_loss: 1497.0442 - val_accuracy: 0.8062\n",
            "Epoch 7/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 2562.0605 - accuracy: 0.6762 - val_loss: 4400.6675 - val_accuracy: 0.1937\n",
            "Epoch 8/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 2316.7261 - accuracy: 0.6793 - val_loss: 919.1937 - val_accuracy: 0.8062\n",
            "Epoch 9/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 1585.2983 - accuracy: 0.6772 - val_loss: 1182.5624 - val_accuracy: 0.8062\n",
            "Epoch 10/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 1310.1868 - accuracy: 0.6779 - val_loss: 406.2618 - val_accuracy: 0.8062\n",
            "Epoch 11/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 1857.8733 - accuracy: 0.6807 - val_loss: 3057.4229 - val_accuracy: 0.8062\n",
            "Epoch 12/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 1356.2905 - accuracy: 0.6818 - val_loss: 402.2443 - val_accuracy: 0.8062\n",
            "Epoch 13/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 2108.9175 - accuracy: 0.6861 - val_loss: 645.4897 - val_accuracy: 0.8062\n",
            "Epoch 14/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 1267.9628 - accuracy: 0.6771 - val_loss: 253.2046 - val_accuracy: 0.8050\n",
            "Epoch 15/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 1883.1593 - accuracy: 0.6825 - val_loss: 3538.9033 - val_accuracy: 0.8062\n",
            "Epoch 16/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 1505.8712 - accuracy: 0.6783 - val_loss: 3370.7163 - val_accuracy: 0.8062\n",
            "Epoch 17/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 1145.1084 - accuracy: 0.6793 - val_loss: 1893.2278 - val_accuracy: 0.8062\n",
            "Epoch 18/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 834.8307 - accuracy: 0.6792 - val_loss: 106.7454 - val_accuracy: 0.7063\n",
            "Epoch 19/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 998.6085 - accuracy: 0.6750 - val_loss: 259.8133 - val_accuracy: 0.4800\n",
            "Epoch 20/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 1081.9792 - accuracy: 0.6692 - val_loss: 464.3719 - val_accuracy: 0.8062\n",
            "Epoch 21/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 1066.2543 - accuracy: 0.6836 - val_loss: 1116.5106 - val_accuracy: 0.8062\n",
            "Epoch 22/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 1067.1816 - accuracy: 0.6762 - val_loss: 2253.6943 - val_accuracy: 0.8062\n",
            "Epoch 23/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 1779.0251 - accuracy: 0.6832 - val_loss: 1299.5408 - val_accuracy: 0.8062\n",
            "Epoch 24/1000\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 763.9929 - accuracy: 0.6836 - val_loss: 97.0158 - val_accuracy: 0.6850\n",
            "Epoch 25/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 1097.0730 - accuracy: 0.6760 - val_loss: 795.6572 - val_accuracy: 0.8062\n",
            "Epoch 26/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 1165.3429 - accuracy: 0.6826 - val_loss: 1242.1248 - val_accuracy: 0.1937\n",
            "Epoch 27/1000\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 620.5369 - accuracy: 0.6878 - val_loss: 791.6223 - val_accuracy: 0.8062\n",
            "Epoch 28/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 1112.6744 - accuracy: 0.6769 - val_loss: 145.2598 - val_accuracy: 0.8062\n",
            "Epoch 29/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 980.5180 - accuracy: 0.6715 - val_loss: 390.7281 - val_accuracy: 0.8062\n",
            "Epoch 30/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 814.7222 - accuracy: 0.6808 - val_loss: 402.6925 - val_accuracy: 0.8062\n",
            "Epoch 31/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 752.1659 - accuracy: 0.6776 - val_loss: 301.3848 - val_accuracy: 0.8062\n",
            "Epoch 32/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 980.7692 - accuracy: 0.6768 - val_loss: 526.4270 - val_accuracy: 0.1937\n",
            "Epoch 33/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 829.8386 - accuracy: 0.6736 - val_loss: 469.6489 - val_accuracy: 0.1937\n",
            "Epoch 34/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 752.2206 - accuracy: 0.6754 - val_loss: 562.1071 - val_accuracy: 0.8062\n",
            "Epoch 35/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 870.7375 - accuracy: 0.6862 - val_loss: 925.2310 - val_accuracy: 0.1937\n",
            "Epoch 36/1000\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 605.2305 - accuracy: 0.6850 - val_loss: 233.1180 - val_accuracy: 0.8062\n",
            "Epoch 37/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 667.2124 - accuracy: 0.6735 - val_loss: 891.3978 - val_accuracy: 0.8062\n",
            "Epoch 38/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 742.3528 - accuracy: 0.6769 - val_loss: 555.0775 - val_accuracy: 0.8062\n",
            "Epoch 39/1000\n",
            "213/225 [===========================>..] - ETA: 0s - loss: 720.0053 - accuracy: 0.6743Restoring model weights from the end of the best epoch: 24.\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 701.6812 - accuracy: 0.6749 - val_loss: 189.9576 - val_accuracy: 0.4812\n",
            "Epoch 39: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0c87165490>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_df = pd.DataFrame(model.history.history)\n",
        "loss_df.plot();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "zAa6-ljHZJHG",
        "outputId": "af1d4baa-e863-490e-decf-7d1cb1eb304a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9d3xb5dn//z6SLMl7j9hJ7MR2ToazE0ICCZAFpaVhNBD2aAst8FCeX/tQKJTV8rTlaUtpobS0oVAoUKDwZTSsBAKEDFKTQdbJsjOdeFtestb5/XF0ZNmWrGHZTuz7/XrxQj46Orql2B9d+lzXfV2SqqoIBAKBYOhiGOwFCAQCgaB/EUIvEAgEQxwh9AKBQDDEEUIvEAgEQxzTYC+gO+Xl5RZgNlAFuAd5OQKBQHC6YARGAJtnzpzZ4X/HKSf0aCL/2WAvQiAQCE5T5gPr/A+cikJfBTBu3DjMZnPED96xYwdlZWUxX1SsEOvrG2J9fUOsr2+cyutzOBzs3bsXvBrqz6ko9G4As9mMxWKJ6gLRPm6gEOvrG2J9fUOsr2+c6usjgOUtkrECgUAwxBFCLxAIBEMcIfQCgUAwxBFCLxAIBEMcIfQCgUAwxBFCLxAIBEOcISX0f9m4j8+PNQ/2MgQCgeCUYkgJ/X2rtvDHbdWDvQyBQDCAvP766/zqV78a7GWc0gwpoU+PN1Nndw32MgQCgeCU4lTcGRs1OUlWDtQ14/Z4MBqG1GeYQCAIwXPPPceqVasAWLRoETfffDPr1q3jd7/7HVarlczMTH7961+zadOmHsfi4uIGefX9y9AS+uR4PCrUtznITrIO9nIEgmHFXW+X89q2Q326hsPhwPxu5zW+NbWQRy+aGfJxR48eZcOGDbz22msALF++nAsuuIAXXniBu+++m1mzZvHBBx/Q2NgY8Fh2dnaf1n2qM6TC3txkTdxPNrcP8koEAsFAsmvXLqZOnYrJZMJkMjFjxgz27NnDBRdcwAMPPMCf/vQnJkyYQHZ2dsBjQ52hFdF7o/jqFvsgr0QgGH48etHMsKLv3igvL2fmzMivIUkSqqr6fnY6nRgMBi6++GLmz5/P6tWr+f73v8/jjz8e8FhxcXGf1n2qM6Qi+hxfRC+EXiAYTkycOJGtW7ficrlwuVxs27aNCRMm8OSTT2Iymbjiiiu48MILOXDgQMBjQ50hFdHnJsUDIqIXCIYbBQUFzJkzh2uuuQZVVVm+fDkFBQXk5+dz4403kpKSQkpKCjfeeCOtra09jg11hpTQC+tGIBh+XHrppb7bV199dZf7LrnkEi655JKQx4Y6Q8q6EclYgUAg6MmQEnoR0QsEAkFPhpTQp1jjMBskqkUyViAQCHwMKaGXJIkMq4mTIqIXCAQCH0NK6AHSrUaqm+1dampPFw7f8yOO/eyBwV6GQCAYYgw5oc+wmrC73DR3OAd7KRFT+9wz1L74/GAvQyAQDDGGpNDD6bdpSnW7cdtsuJttg70UgUAwxBiCQm8ETr/KG3djo/Z/m+20tJ0EAsGpy5DaMAWnb0TvatKEHo8HT1sbxsTEwV2QQHCa0NLSwg9/+EPa2tqw2+389Kc/pbm5md/+9rcYjUYuvPBCbrjhBj7//PMexxYuXMjbb79NYmIiv/rVrygtLQXg008/pbq6mscee4xnnnmG7du309HRwbx585g5cybHjh3j7rvvxu12k5+fz7333suKFSt47733kCSJt956i507d3LPPfcM8rujMeSEPt0r9KdfRN/QebvZJoRecNqxuWIVlbXb+3QNh8PBwc0f+n4uyprC7DEX9vqYmpoali9fzuLFi9mwYQN/+ctfUBSFl19+mdTUVG699VZWrFjBQw891ONYMKqqqnj55ZdxOBwUFBRwzz33YLfbOeecc/jRj37EY489xg033MCiRYt49NFHOXz4MLIss2XLFmbMmMGaNWv4zne+06f3IpYMOaH3WTen2e5Yl7/Q22yQN2IQVyMQnD5kZWXxxz/+kZUrV+JwOGhvb8disZCRkQHAn//8Z+rq6noc643JkycjSRIWi4WmpiZWrFhBXFwczc3aTOpdu3Zx7733AnDXXXcBsGzZMlatWkVZWRlHjx5l8uTJ/fWSI2bICX2mbt2cbhF9Q2PnbZGQFZyGzB5zYcjoOxTRtCl+7rnnyM3N5f/+7//46quv+MlPfoLH4+lyjsFg6HGsO05nZ6WePnHqiy++YOPGjTz//PPExcUxZcoUAIxGY49c2oIFC3j88cfZuHEj5513XkSvob8ZcsnY09W68Y/oPTYh9AJBuDQ0NDB69GgAVq9eTWJiIm63m5MnT6KqKrfccgtGo7HHMZvNRlJSEjU1NbjdbrZt2xbw2nl5ecTFxbFmzRo8Hg8Oh4OysjI2btwIwOOPP8769euJi4tj9uzZ/P73v+eiiy4a0PcgFENO6FPNRgzS6dcGoatH3zyIKxEITi+WLVvG3/72N2666SamTJlCTU0N3/72t7njjjtYsWIFc+fOJSUlhQceeKDHsWuuuYbvfe973H777ZSUlPS49rx58zh06BDXXHMNR44cYfr06Tz44IPccccdvPLKK1xzzTUcPXqUOXPmAPC1r30NSZIoLCwc6LehV4acdWM0SGQlWk67DpaubslYgUAQHlOmTOHdd9/1/bxo0SJAmxvrz9y5c5k7d26XY5dffjmXX3550GsnJyf75tCC5t3r1tKzzz7b4/z169f3muQdLIZcRA9au+LTzbrp4tEL60YgOO24+eab2b9/PxdffPFgL6UHQy6iB61d8VdVjdidbqxxxsFeTlh0rbppGsSVCASCaHj66acHewlBGZIRvd6XvuY0iuq719ELBAJBrBiSQp+brM2OPZ1KLF1NnVG82yaSsQKBIHaEZd3IshwP7AB+BqwBngeMQBVwraIoHbIsXw3cCXiApxVFWSnLchzwLFAIuIEbFUU5GPNX0Q09oj+dErLuxgYwGsHtFhG9QCCIKeFG9PcB9d7bDwNPKooyH9gP3CTLciJwP7AYOBf4b1mWM4CrgEZFUc4GHgF+EcO1ByUn+fQbKehqbMBcMBIQ1o1AIIgtIYVeluXxwETg395D5wJveW+/jSbuc4DNiqI0KYrSDnwOnAUsAt7wnrvae6zf0a2b06WWXvV4cDc2Ys7PB0kSVTcCgSCmhGPd/Aa4Hbje+3Oioigd3tvVwAggD6jxe0yP44qieGRZVmVZNiuK4gj1pDt27AjvFQSg7kgFAF8dOER5WkeIswee8vLyLj+rzc2gqrRIRkhMpKX6ZI9zBpLBfO5wEOvrG8NxfXfccQePPvooVqs14P0333xz2FUzp/r7F4hehV6W5euADYqiVMiyHOgUKchDIz3eg7KyMiwWS7in+ygvL+fc2dPh/QpISIm4b0Z/E6iXR0dlBduBzKIimo8cQnK5mDJI646m18hAItbXN4br+iwWC9OmTSMxSFdYk8kU1vOeyu9fR0dH0AA5VET/dWCsLMvfAEYCHUCLLMvxXoumADju/S/P73EFwEa/49u8iVkpnGi+r2QnnV4evV5Db0xLx5icgvPkiUFekUAQOUfuvYv6N/7Vp2t4HA62mc2+nzMuuYxRjzwa9PxLLrmEJ598kvz8fI4dO8Ztt91Gbm5ul970eiOycFAUhYcffhiDwUBiYiK//OUvMRqN3HnnnTgcDurr63n00UcZPXq075jD4eD+++9n0qRJfXrt/UmvQq8oyhX6bVmWHwQqgXnAZcAL3v+/B2wC/irLchrgQvPi7wRSgOXA+8BFwMexfgGBsMYZSbXGRSz0B+uasZqM5Kcm9NPKAuNu0ITelJaGISUZ9/69qKqKJIX9BUggGJYsXryYjz/+mKuvvpo1a9awePFixo8f36U3/R/+8Iewr/fII49w1113MXXqVFauXMnf//53xo8fT25uLv/7v//LqlWrqKur49ixY75jR44coaKioh9fZd+JZmfsA8DfZVm+BTgEPKcoilOW5bvRBF0FHlIUpUmW5X8CS2RZXof2beCGGK07JLnJ8RFNmVJVlXOeeJ+C1AQ23tm3VquR4vKOETSmpWNKSUV1OlE7OpCC+IkCwanIqEce7TX6Dofy8nKmRmCNLF26lF/+8pc+ob/nnntYuXKlrzd9QkJkQduBAweYOnUqAHPmzOGJJ55gxYoV/O53v+P+++9nzJgxXHjhhVRXV/uOLV26lAULFkT0PANN2EKvKMqDfj8uCXD/a8Br3Y65gRujXVxfyEmysr+2GbfHg9EQuoq0usXOcVs7Vc3tNLY7SIs3h3xMrHB7xwia0tMxJKd4jzVhEEIvEPRKaWkp1dXVVFVV0dzczOrVq7v0pn/00eg/eJxOJwaDgZycHN588002bdrEU089RWtrK7fffrvv2EsvvcTWrVu5/fbbY/jKYsuQ7HUDWi29R1Wpa+0gx1tu2Rv7arTdqKoKGypr+NqEgv5eog/dozelpWFM8Qp9s4243NwBW4NAcLpy7rnn8thjj7Fw4UIaGhrQC0dWr17dZZhIOJSWlrJlyxamT5/O5s2bKSsrY/369TidTs455xza2tp4/fXXuxwrKSnhwQcf7IdXFjuGrNDn6rtjW+zhCX1tZ+36+srqARV6d5dkbLJ2TGyaEgjCYsmSJaxYsYK33nqLtrY2fvzjH/Pee+9x9dVX88477/Cvf4WfIL7vvvt46KGHkCSJ1NRUfvGLX9DY2Mj//M//8Ne//pWWlhbuvfde8vLyfMckSeKOO+7ox1fYd4as0OttEKqb7VpFfwj213b2l1lfUdPLmbHH5W1RbPJW3YBoVSwQhMuUKVPYtWuX7+dAvekvu+yyXq+xadMmAEpKSnj++ee73JeUlMRLL70EdC2v1I+dDgxdoY+wsdm+Gk1Yc5KsfHGkFqfbQ5xxYHq+dUb0/taNaGwmEMSSNWvWBBwWct1117FkSY+045Bi6Aq9L6IPr7HZ/tpmEs0mlpWN4i8b97HteAOzRmX25xJ9dK+jB2HdCASxZtGiRb4If7gxJNsUgzZlCsLbNKWqKvtrmynJSuasMTkArK+o7tf1+eNubEAymzHExwvrRiAQxJwhL/Th1NJX2dppdbi8Qp8NwOeVA+fTuxobMaalI0kSxhSRjBUIBLFlyAp9TgRtEPZ5E7Gl2SmMyUgiLzme9RXVqKrar2vUcTc0YEpLBxDWjUAgiDlDVuiTLXFYTcbwhN6biC3JSkaSJOYWZXPc1s6hhtb+XiaqquJqasSYngZ0Cr1HTJkSCGLGwoULaW3t/7/nU5UhK/SSJJGTbA1rypReWlmapYmsz74ZAJ/e09ICbndnRJ+aCoiIXiAQxI4hK/SgbZqqbrGHtGD2eiP60mzNH59XpAn9+gHw6f0rbsDPurE1BX2MQCDQuOSSSzh+/DgAx44d4+KLL+aWW27h2muvZfny5Wzfvj2s6zzzzDNcccUVLF++nCeeeAIAm83GzTffzFVXXcUtt9xCa2srra2tPY794Q9/4IUXXgBg7969XHvttYDWh+fOO+/k1VdfZf369VxxxRVcc8013HrrrTgcWhPfn//851x++eVceeWV7N27lzvvvJMNGzYA4HA4WLx4MS6Xq8/v05AtrwStDULHEQ82u5PUXnrX7K+1kWyJ8/n60wsysJqMA7Jxyu1rf6AJvSEpSTsuqm4Epxlb7voHh1/b2KdrdDgcHPVrUzz6W2cy/dGrg54fy+6VL774IgaDgUWLFnHDDTewcuVKzj77bK677jqeffZZNmzYwIcfftjjWDCOHDnCk08+SWlpKe+++y6//vWvGTVqFHfddRfr1q3DarVy4sQJXnnlFTZv3syqVatYtmwZq1atYu7cuWzYsIEFCxZgMvVdpod0RJ/j1wYhGB6PyoHaFkqzk31tgc0mI2eMzuSrEw00tfdv+3yXt0WxbtlIBgOG5ORhuWHq2M8eYP/Vl/veE4EgFEuXLuWjjz4C8An9+++/z5VXXsmvf/1rGr2dYUNhtVq55ppruO6662hoaKCxsZFdu3YxY8YMAG644QYWL15MRUVFj2PBiI+Pp7S0FICMjAzuu+8+rrnmGjZt2kRjYyM7d+70XWv27NnceeedzJ8/n/LycpxOJ2vWrOGiiy6K+r3xZ0hH9P6zY8dlpwQ852hTG3aXm5Ks5C7H543J4dOD1Ww8VMv54/P7bY3uxs7OlTrG5JRh6dHXvfZPOg7sp13Zw7jX38YyunCwlySIgOmPXt1r9B0OkU5wikX3ymPHjvHss8/yxhtvkJiYyDe+8Q0AjEYjHo+ny7kGg6HHMf+5Ef42S1xcnO/2T37yE55++mmKi4t5+OGHg17fZDJx1llnsWHDBvbt28f06dPDfCd6Z0hH9J2NzYInZPWKGz0Rq6P79Bv62afv7tGDV+iHoXXjbmoCgwH7nl3sPu8sWrdtGewlCU4DunevHD16NBB+98qGhgYyMjJITExk586dHDt2DKfTSVlZGRs3albUyy+/zBtvvEFxcXGPY0lJSdTUaDoRbJ5sS0sLI0aMwGazsWnTJpxOJ5MnT/b12Nm1axcPPfQQAMuWLeP3v/89Z5xxRt/eGD+GtNCHM1JQr6Evye4a0c/1JWT7t/Kmu0cPYExJHpYRvdvWROLMWYz61W9wVp9kz/nn0fThe4O9LMEpzpIlS3jnnXe44IILWLZsGX/729+46aabmDJlCjU1NSG7V06YMIHExERWrFjBqlWrWLFiBQ899BDXX389W7Zs4dprr2Xt2rUsWbKECy64oMexJUuWsGbNGm688UZsQQK0q666iiuvvJKf/vSnfOc73+HPf/4zhYWFFBcXc9VVV/Hzn/+cFStWANq87KamppjZNjDkrRu/DpZB2F8bOKLPSLAwITeVjYdqcbk9mPqpwZnPo09L8x0zJqegdnTg6ejAEMWA9NMRj92O6nBgTEkl77YfYC4YxcHvXMfeby2j6PdPkX39TYO9RMEpSl+7VxqNRlauXBnwvqeeeqrLzwkJCT2OJSUl8c477/h+vu2224DOjpgAP/jBD/jBD37g+/mSSy4B4O677+7xnBUVFRQUFFBSUhJ0zZEypIXel4ztRej1gSOl3Tx60Oyb3Seb2F7VwIyR/dPgLJhHD1oHy+Ei9O4mrZzUmKIlpTMuvpS4vDz2X34JlbfdjOPwIfLve3AQVyg43Tkdule+9NJLvPLKK/zyl7+M6XWHtND7krG9WDf7a22kxZvJTOwpqPOKcli5aT/rK2r6TegDevT+U6aysvrleU819H0DevURQPKZ85iw5jP2XvoNjv/qETqOHEa96ZbBWqLgNOd06F555ZVXcuWVV8b8ukPao89MsGCQpKCtit0eDwfrWijNSu6SOdfpbHDWfz69b15sWs+I3jOMfHqXLvQpXS00a+k4JqxZR+Ks2dS9+Dzqz+4fjOUJBKc1Q1roDQaJ7CRL0Ij+cEMrDrenR2mlTklWMtlJln7dOOVqbEAymTAkJvqO+SL6YVR5o0f0ppTUHvfF5eQgr1qDdfxE+GwtngjngAoEw50hLfQAuUnxQTdM+XetDIQkScwryuFoUxuH+6nBmbuhs0WxTqfQD582CO4m7UPNkBz438KYkEDi9Bng8eA4emQglyYQnPYMeaHPTrJgszuxO9097tvvTcQGi+gBzirq3wZnrsaGLhU30DUZO1zwRfSpPSN6HUvRGAA6Kg8OyJoEgqHCkBf63hKy+/TSyiARPWg7ZKF/Gpypqoq7sQFTN6E3DMMpU75kbADrRkcXekdl5UAsSSAYMgwDoddLLHsmZH3WTS8R/YyRGVhMhn4ZLehpa0N1OrtU3ADDcsqU/qHWPRnrj6WwCICOQxUDsSSBYMgw5IW+t8Zm+2tsZCZYSE8IXqtuMRmZNTKT7VWNNNtjmwQMtCsWGJZzYwOVV3bH7LNuKgdiSQLBkGEYCH1nYzN/XG4PFfUtvh70vTFvTA4eVWXT4dqYrq1zV2wQoR9WHr0e0fci9CPywWQSEb1AECFDX+j1NgjdGptVNrTg8qiUZAW3CnR8g0hibN90RvTdkrEpw29ubPedsYGQjEbIG0FHhRB6gSAShrzQ5wZpbKa3PhgXTkSvV97EOCHr0sUtXVg34Vg3AIzIx1Vbg7ulZQBWJRAMDYa+0CcH7nejNzMLJ6LPSrIiZ6ew6VAt7m79o/tCcI9+OCZjm5CsVgzm4JPAABihzQboOFTZ/4sSCIYIQ17ofa2KmwNH9OF49ADzxmTT3OHkq6rwJtaEQ6A+N4C2UzYhYdh59L3ZNjqSV+gdwqcXCMJmyAu9xWQkLd7c07rxlVaGjuhBa3AGxLQdgrshsEcPmlc9rHrdNDX1ulnKR543oheVNwJB2ITsXinLcgLwLJALWIGfAduA5wEjUAVcqyhKhyzLVwN3Ah7gaUVRVsqyHOd9fCHgBm5UFGVAtzbmJll7TJnaX2sjN9lKsjUuyKO64t/g7Naz5Zisy+VtUdx9ZyxoPr2rKXbfHsKh+pm/oB48CBGMcosVblsTllGjQp+oWzeVIqIXCMIlnIj+IuA/iqKcA1wO/BZ4GHhSUZT5wH7gJlmWE4H7gcXAucB/y7KcAVwFNCqKcjbwCPCLmL+KEOQkW6lt7fD56w6Xm8r61rCjeYBx2SlkJVr49MBJVFWNybqCefSgbZoa6Ij++C9+hvq3vwzocwJ4HA5Uuz0s64b8AkBsmhIIIiGk0CuK8k9FUfQJu6OAo2hC/pb32Nto4j4H2KwoSpOiKO3A58BZwCLgDe+5q73HBpScJCuqCrWtHQAcrGvBo6q99rjpjiRJLCodwXFbO7tOxqbZWDCPHrSI3tPePqCdGl0N9dBsQ41hwjkcfKWVQRqadSElBUNysrBuBIIICNujl2V5PfAimjWTqChKh/euamAEkAf4G9g9jiuK4gFUWZZDlFbElu6Tpjp73IQv9ABLZc02+FA5HpN1uRsbwGDwVdn4Y/D1pB+YhKy7rQ3VbgePZ8DLOsMurUT7wLUUjqHjUEXMvlkJBEOdsCdMKYoyT5blacALgP+Ujp4TO6I73oUdO3aEu7QedJ/E7m7WIufPt2zHWZXEx7vrADDYaoNObQ9EbocWXb+6eQ/zkwIPM4lkfZ6qKkhK4sstW3qco0fyW9d/7qs06U/U6pO+21s/+xTJa5EMBKqyG4Bau536MP492tPSoKWF8o/WIAX4NjTYRPI7NRiI9fWNU319gQgnGTsTqFYU5YiiKFtlWTYBzbIsx3stmgLguPe/PL+HFgAb/Y5v8yZmJUVRHKGet6ysDEsU81LLy8uZ2S2Z+B/HXviqhpS8UcycOZaVFZuAk5w/ZypT8zMiun7Zxhq21jQzaco0rHHGPq1vq92OISubKQGSn4eKxlANTCwqJKFsSsTPEyltX21jp/f2+PwRJA1gQtbW3IQC5JeUUhDiecvLy8mdOo2T6z5lfGrKgK4zHAL9/p1KiPX1jVN5fR0dHUED5HCsmwXADwFkWc4FktC8dn2s+mXAe8AmYLYsy2myLCehefGfAR8Ay73nXgR8HN3LiJ6cbrtjfZulMiOzbgCWyCOwu9x8dvBk6JND4GpqDOjPg9+mqQGyUVz19b7b7ob6Xs6MPfp+gXCsGwBL0VhAlFgKBOESjtD/CciRZfkz4N/AbcADwPXeYxnAc97o/m7gfbQPgocURWkC/gkYZVle533sPbF/Gb2T223T1L7aZvJT4km0hFda6Y/Pp99b1ac1eex2VLs9YA09DHy/G3+h9789EITTi94fS1ERIDZNCQThEtK68Qr4VQHuWhLg3NeA17odcwM3RrvAWKA3NjvZYsfudHOksZUFY3Ojutb8sTlYTUY+UI7z6EXRf4XrreIG/PvdDEwy1tUwiEIfRkMzfyyFol2xQBAJQ35nLGhzY0Gzbg7UNaOqvY8P7I34OBPzx+bwVVUjVba2qNfUuSs2iNAPeERfF/D2QNBZdRPevgazPoBEjBQUCMJiWAh9ksVEfJyR6uZ29tV4Sysj2CzVHd2++UCJ3r7pjOgDR7EDLfT+vrzeJ3+gcEVo3RgTEzFl54jGZgJBmAwLoZckiZwkKyeb7ez39rgpibCG3p+l8gigb/X0ve2KBT/rpik2m7NC0dWjH+iIXvswM4Up9ACWMWNwHDmM6u459F0gEHRlWAg9aO2Kq1vsnZulorRuACblpZGfEs+He6vweKLbtNPZ5yaUdTPwHv2AV91E6NGD5tOrTieO48f6a1kCwZBh2Ah9TlI8DreH8iOaiBX3QeglSWKJnE9tawdbj0cniiE9et/O2AHy6OvqwGAAk2kQPfpIhL4IEM3NBIJwGEZCr1XebDvewKi0BOLjwt4UHJAl4zT75oMo7RufR58epLxygKdMuRoatA+dlNQB9+jdtiYksxmD1Rr2Yyy+QeFC6AWCUAwbodcnTXlUtU+JWJ0l40YgSfBhlAlZt7cFcbCI3jDAU6Zc9XUYMzIgJaWLjTMQuJts4TU080OP6B1C6AWCkAwbodcjeuhbIlYnK8nKjIIMPq+soaUj8g6ToTx6g9mMZLUOiNCrqoq7oR5TRgakpOJuaBjQJKfb1hSRbQNgGePdHSsqbwSCkAwfoU/uFPpYRPQAS+R8nG4Paw9E3g4hVNUNaPbNQGyY8rS0oDqdmNK1iB5VHbBqH/AKfQSJWADzyFFgNIq+9AJBGAwboc9NjvfdjnazVHf60rbY1dAAktRrJGtMSRmQiF63akwZmeAV3IFKyHqcTjxtbb4qo3CRTCbMI0eJ3bECQRgMG6H3t25Ks2MT0c8tzCLJYopq45S7sRFjSgqSIfg/gTF5gITeK+q+iB4GzKf3eJPNkUb0oPn0zqrjeNqjbxktEAwHho3Q643NDJLE2MykmFzTbDJybnEee2tsVNa3RPRYV2NDD39eVdUuwzSMycmardLPfnlnRJ+BNMARvSuK0kodX+XN4UMxXZNAMNQYNkKfkWDBaJAYnZ6AxRR5H/lg6LtkIy2zdDc2dPHnVVXl3Cc/4NwnP8Du1IRdFz93S2QfIpHiqtOE3pieAcl6RD8wJZb6PoGoInpd6IVPLxD0yrAReoNB4sHzp/KTxZNjet1o2hZ7HA7Nl/ZrUfzJgZOsq6hmXUU1d7zxBYO30E0AACAASURBVOBfS9+/iVG3v0fv/XBx1Q1QRO9N+poi9OihU+gdwqcXCHqlb7uGTjNiLfKgJXaLMhJZs7cKl9uDyRj6szPQrtg/rd8LwKi0BFZu2s8Zo7NYMkCbpnwefUY6eMs+B6oNgv7aorJu9N2xIqIXCHpl2ET0/YUkSSyV82myO9l8JLwouHNXrCb0VbY23vjqMJNHpLH2tvPJSDBzxxtfUO39HO7vhKwrUEQ/QD3pIx064o/PuqkQQi8Q9IYQ+hiwZJzetjg8n75zV6xm3TyzaT8uj8r35skUZSTx/NVn43B7+IdSC/R/vxtd1E1dPPoBEvooGprpmHJyMcTHi01TAkEIhNDHgIWleRgNUtjtEPynS7ncHp7esI8ki4mrZ2gR6gXjC3jw/Kkcd2tJY2c/b14KHNEPjEcf6dARfyRJwlw4Rlg3AkEIhNDHgLR4M3NGZ7HpcC0NbR0hz3c3dva5eWfXUY42tXHtzLEkWztn2P5k0WRKirSKnv+3cXf/LNyLq74OyWTCkJyMZLEiWa0DVnXTF+sGtPmx7sZGX0sJgUDQEyH0MWKpnI9HVflo/4mQ5+oiakxL9yVhvzdvXJdzDAaJW5fOAmDttv28vfNIjFfcibu+AWN6BpIkAVpk7x6oiL7Jm4yNsKmZjm9+rIjqBYKgCKGPEUsiqKfX+9ycJI4P91Yxf2wOZSN69rxJycoAINVl5/oXP2d/bf949a76Os2f92JKzxg4j74PG6ZAi+hBJGQFgt4QQh8jZo/KJDPBwj+3HOJAbe+NyHSP/s3D2nndo3kdvf/LRUVpNNmdfOvZT2hzuGK4alA9HlwN9Zgy/YQ+IwN3UxOqK7bPFYg+WzciohcIQiKEPkYYDQZ+s2wWzR1Ornz+UzpcwdsW6B79SwcayEmycunk0YGv6bUz5AQD35s3jq+qGvnBG5tjum63zQYeT4+IHgZmd6zL1gRGI4aEhKgebxkjNk0JBKEQQh9Drp01lutnF1N+tJ57/v1l0PN0AT2qxvHtOSWYg7Rk0KNct83Gb5fNojQrmX98eZB2Z+wi7S4VN1702wNReeNusmFMTfXlByJFRPQCQWiE0MeYP1wym/E5KTz+6R7e2hE4gap79K3WBL57ZmnQa/kGhNuasJiMfH3iSDpcHtZX1MRsvbqY65u3AIwZ2u2B8OndtiZMUdo2oL1HxoyM08Kj9zidotOmYFAQQu+Hu7W1z3+IiZY4Xr5uAVaTkZteXs/hhtYe5zTX1NIaZ+WCSYUUZgTvpGmwWJDMZt/O2IWleQBhVfaEi7uXiH4gKm+iGTrSHUvhGDoOV6J6PDFaVf9Q8b1v89WsyQM6vUsgACH0PlSPh51nzWLvZRf1+VqTR6Tzu0tm09Du4OoXPsPp7ipAzTV12CyJQZOw/vhPmVowNheTQeKjfdHNqQ1El12xXgbKo1fdbjwtLREPHemOpbAItaMD58nYfQD2B81rP8JxqBK7smewlyIYZgih99K2bQsd+/fR/Ola7Pv39fl635lTwuXTCllfWcOD72/zHbc53Biam+hISOJ8b+fL3vCfMpVsjWPO6Cz+c6SexnZHn9cIfkIfyKPvZ+vG3ax9gEVbWqmjJ2Q7TuFB4a76et8HUevW4PkbgaA/EELvpWn1B77b9f96pc/XkySJPy8/k+LMZH65Zgfv79Hq69/dV0ei005abjYGQ+gEpDE5pUuvm4WlI/CoKp9EMac2EJ3TpTo9ev12f7cq7mtppU5nQrayr0vqN9p37/Tdbv2yfBBXIhiOCKH30vTh+2AwIJnN1L36zy6TnqIlxWrmpWvnE2c0cP1L6zje1MZ7O44BkD9qRFjXMCYn425u9vnPPp8+RvaNbs+YMgNF9P1r3cRM6H2bpg72dUn9RvvuXb7bbVuF0AsGFiH0aMMvWjZtIHHWbFLPvxD7nl2079wRk2vPHJXJ/100g5qWDs558n1s9Zp4JvgJa28YUlJAVfG0akndMwuzSDAb+WhfbPzozqqbTo/emJHR5b5w8XhUPJ7wPyA7O1f21aP31tKf0hG9JvSS1Urb9m0DshlNINARQg/Y1n4Ebjepi5aSuXwFAPWvvRyz699+9ni+OWkkB+taSO5oA+gyXao3fFOmvPaN2WTk7DG57DrZRJWtrc9rC1h14xX9SIePfGPlRyx44v3wn7uP7Q90zKMLQZJOaY++fdcOkCTSv/5NPG1ttIuErGAAEUIP2Lz+fOqS80m94EIMSUnUv/ZKTOwb0Pz6lSvmUZyZzBSLFsmZ0nr2tgmEMcCUqUU++6bvUb2rvg7JbO6yM9VgsWBITIxo+Eh9WwcfKMfZcKgm7A8g33SpKBua6RgsFuLyC05xj34XlqIxJJ81H4A2kZAVDCBhjRKUZflRYL73/F8Am4HnASNQBVyrKEqHLMtXA3cCHuBpRVFWyrIcBzwLFAJu4EZFUU4ZM1VVVZpWv48xPZ3EmbORjEbSvv5N6v/5Iq3/+YKk2XNi8jwZCRa2/89FbPuN1nLYGK7QpyQDXadMLfQT+qtnju3TulwNDZgyMnvsTI20sdknB06ify6ur6zhsimFIR/Tl6Ej3bEUFtGycT0ehwOD2dzn68USZ00Nrtoaks6YQ8L0GYCWkM26+rpBXplguBAyopdl+TygTFGUucAFwO+Ah4EnFUWZD+wHbpJlORG4H1gMnAv8tyzLGcBVQKOiKGcDj6B9UJwy2JU9OI4cJnXhEiSj1oogc/kVANS/+s+YPpc1zoixVSsp9K9y6Q1fGwQ/oZ+Wn0FGgpmP9p/o87eO7p0rdUwZmRF59Gv9NnFtqAxv566rD0NHumMpGgMeD44jh/t8rVijV9xYJ0wkoWwKkslEq0jICgaQcKybT4Hl3tuNQCKakL/lPfY2mrjPATYritKkKEo78DlwFrAIeMN77mrvsVOGptWap5yyeKnvWMrCJRjT06l//dXY72Js8daOR+rRN3UKvcEgcW5JHocbWjlQ13unzN5Q3W7cjY2YMnoKvTE9HU9LCx5HePX6a/efJD7OiMkghS30saq6gVN7ULieiI2fMAlDfDzWCZNoFwlZwQAS0rpRFMUN6Pv4vw2sAs5XFEUfpVQNjADyAP+/8B7HFUXxyLKsyrJsVhSlVwXZsSP6qpfy8vCjJc/rrwFwKCePw36P85y1APc7b1L+zF+RZsyKei3dUb2bhPafOIkUxjrVOs0+OfjVdipGF/mOl1i0t+9vq7/g0tLwvh30uHZTE6gqzZKhy3tWXl6OR9JigC/XrkUKUSHUYHex40QjZ+Ql0uxw858jtXy+aTNWU+9xhGf/AQCUo8fCei/819fjtaBZT/s++QQptecH10DSfX2eTz8BoFKVOFRejmd0IXy1jfLX/4VUXDLo6zvVEOuLPWF59ACyLC9DE/qlgP/W0WC7fiI93oWysjIsFku4y/NRXl7OzJkzwzrX097Ol9u3Yi2bQtn5F3S5z/b921HeeZOsbVso+u4tEa8jGJu9Qj/pzLnEj5NDnt9w/Cj7gZGZGeT5va7k0TYe3fwm+x3msF9vd+z79/EVkFVczBjvNfT3r3JsMTVr1zBp1EjiJ0zs9TqvbjsE7OWb00upbrGz+7M9qNmFzByb0+vjDljM1ANT5s7FXDAyrDUH+/dttrex5xcPk4uHUVG+H7Eg0Pp215ykxWBgxsWXYIiPp3rxUg79+y2KHHayBnitkfx9DAZifdHT0dERNEAOq+pGluXzgXuBrymK0gS0yLIc7727ADju/S/P72E9jnsTs1KoaH6gaF73CardTuqSpT3uSz57AXF5I6h/6/Ww7YuwaNEsmPCrbrzJWFvX6VKlWcmMTE3g430nIqpd9yfQrlgdUwS19Lo/f25JHnOLsoHwfPqYWjdFp2ZfelVVad+zC8vYYgzx2p+Mf0JWIBgIwknGpgL/B3xDURS9DGM1cJn39mXAe8AmYLYsy2myLCehefGfAR/Q6fFfBHwcu+X3jaYPvWWVi3oKvWQ0knHpctz19dg++jB2T9ocoUef0rWO3rc+SWJhaR51bR1sOx7dDtZAveh1fEIfxu7Yj/edINFsYtaoTOZ5hf7zyuqQj3PbmsBgwJAUvINnuMSNyEcym+moPGUKugBwVZ/EXV9P/PjOb0UiISsYaMKJ6K8AsoBXZFleK8vyWrTqmetlWf4MyACe8yZg7wbeR/sgeMgb/f8TMMqyvA64Dbgn9i8jOppWf4AhMZGkuYHzwxl69c1rfe9946O5GUNCQtglgHoy1mPrmXRdWKq1UYi2HUKgzpU64Q4fOd7UhlJjY/7YHOKMBkamJTI6PZENlTUhK4LcTTaMKSm+0s5/bqnkqc+VaF4KksGAeXQhHadYRN++S6u48be/DFYr8RPLxA5ZwYARTjL2aeDpAHctCXDua8Br3Y65gRujXWB/0XGoEvvePaRd+A0MQXIBibPOwFI0hoZ33sTd1oYxynF3XWi2hV1DD8EjeujcOLVm/wl+eN6kiJeiC73RK+pvfHWYvYdtzJzZ2RIhVC39Wm9ztfNKOl27uYXZ/HNrJftrmynNDl466W62+Wwbh8vN917biM3uZG5RNtMKIk+oWkaOwrZ/Hx67HYPVGvHj+wP/iht/EmbMpG37Vtr37CKhbMpgLE0wjBi2O2P1bpWpi88Peo4kSWR863I8LS00vf9ubJ64pTlsfx7AkBxc6PNTE5iQm8pnB0/i6GVGbTDcfh59a4eT615cxwPrj1Hf1hG2R+/vz+v47JsQk7D8h458cuAkNrsTgIf82jpHQlx+AQCO48eienx/4BP6iV0T2onTvD79FrFDVtD/DF+h/7Bn/XwgMr6lb57qe+8b1e2Glpaw/XlAS+AZjQGFHmBhSR5tDjebDtdGvB5f58qMTN7aeZQ2hxunR+WlLys6+93U9+7Rr91/klRrHNMLOj+85o3xJmQPBffpVY8Ht83m+8bypnfsYk6Slbd2HqX8SOQtks1eoXeeSkK/ZycYjVhLu1ZY6QnZNpGQFQwAw1LoPU4ntk8+wlJcgnVsca/nxk+ajHX8RBrfX4XLu2U/WvQt/+HuigXtW4UxpXPKVHcW9qHvja/qJiODl7ZoG40MEvztiwNhefT6hq35Y3MxGjp/laaMSCfBbOy18sbT0gKqijE1FVVVeWvnUdLjzTx7pZYveTCKqN58ikX0qqrSvmsn1rElPezBhLIpSHFxXRKytS12DtRGvwFOIAjGsBT61k0b8DQ392rb6EiSRObyK1A7Omj891shz+8NV1MjEH6fGx1jckrQiP7ckjwMkhSd0Hv99yZzIu/vOc60/HTOLkhmy7F6drSpXc4JxMde2+a8ktwux01GA3NGZ7HzRFPQSVguv9LK8qP1HGtq4xuTRrJUHsGCsTms2n2MTYciG4Ie563FP1WE3ll1HHdTE/ETe+ZPDBaLlpD9ajsep2ZZXfXCZ8x+7N/YnWKmrCC2DEuh19seBKqfD0Ss7Bt3o9cqicC6AU0M9Zrz7qTFm5k5MoONh2po6XBGdF1XfT2G+Hje2FeNy6OyYvoYLhqrre25rYcxpqT02sFS9+fPK83rcd+8Im2zVLCo3tfQLDmFN3do/WmWlY1CkiQevGAaAA++vz2i12PO10YzOo8fj+hx/YXe4ybYhrOE6TNQ7Xbse3bRbHfyyYGTNNmd7DrZOJDLFAwDhqfQf/gBktlM8vxzwzrfWlxCwoxZNH20Gmdt5F64jssr9JFH9Mm4bbag5YoLS/NweVQ+Oxi6dt0fd0M9xoxM/rmlEoArphdxVn4SOUlW/lF+EENaetCIXlVV1h44SWaChcl5PV9PqI1Tbr+GZm/uOILVZGTpOK1c9JziXBaV5vGBcpzPK8J/TeZ8b0R/7GjYj+lPglXc6CRO13ZYtm75krUHTuDybnzbeqx/J3sJhh/DTuidJ0/Stm0LyfPOxpiYGPbjMpdfAW43Df/vX1E/t7tBi9QiqboBb4mlx4OnLXCf9856+sjsG1d9HWpKGp8cPMnZY3IYnZ6IySBx7ayx1Lc5aIlPDjp8pKK+hcMNrSwozg04+/bMwiwgtNA3Ga3sPNHE4nEjSLTE+e5/4PypQGQVOKbsbKS4OBxVp4Z10yn0gSP6RL8dsqv3du6F2Hqsf4eyC4Yfw07om7y7XFOWhPbn/cm4dDlIEvWvvxr1c3dG9BFaN72UWAKcNSYbi8kQ0cYpj9OJ22ajNi4eVYUVM4p8990wW0tQH1XNeNra8NjtPR4fzJ/XSU+wMCkvlU2Ha3G5PT3u17txftWi+dHLykZ1e005LJXzWbPvRNiD0CWDgbgR+TiOnSpCvxPJZMJSUhrw/vhJk5Hi4mjbqgl9gtmIQZKi3uksEARj+Am9t6wynESsP+aCkVhLxtG+46uonztqjz7AlCl/4uNMzCvKZuvxBmpbeopywLV4SysrXCZMBonlfoNCJualcWZhFgc9WoQdyL5Zu18TX//6+e7MLcqm1eFie1VP4dIj+k31DiQJvjGxoMc5D56vbSR68L2tYffdN+fn4zxRFfv20hGiqqo2VapkXNBd0AaLhfhJk2n9ajv7quo5pziP8TkpbDveEHX/IoEgEMNK6FWPB9uaD4nLLwhYCREKS3Exrvq6sPq/BCJqjz7AlKnu6PbNx2FGv7p4V6pmFo8bQVZS152k188upsmsWVuuuq4llqqq8vH+E+QkWZmYG7wh2dzC4AlZXei/bHJyVlEOOcnxPc6ZU5jNhRMK+PRgddi2VFz+SHC7cVaH9z70F46jR/A0N4fs/Jk4bQZ0dDC24ThLxo1gWkEGzR1ODtaLMktB7BhWQt+29UtcdbWkLl7aY3ReOFjHar3DOyoORPX8UXv0vn43vQm9Xk8fnn2j18fbLIlcOWNMj/uvmFZEW6L2AdM9ot9bY6PK1s65Jbm9vo9njQm+Q1YX+pa4+B62jT8Per36B9/fFlZUr1feDHaJZaiKG52EGVpCdnxtJYvHjWBavva7IRKyglgypITetvYj1DdepeGdt2jdUo7z5ElUT6c/HK1to2Pxbq6yH4hO6H0RfQQbpsC/DULwKG/WyExSrHG8ueMIDW0dQc/zrcVbNtmWkMKyST2FNjXezJgx2vHtu7p2hPw4DNsGoCQrmaxECxsC1MPrHn2LOZ5vlgXvRT9zVCbfnDSS9ZU1fKCE/hDz7Y4dZJ++s/VBWa/nxU+dDsDMxiNMzE1lqrfHz7bjIiEriB1DSugrf3Ar6u9+zf4Vl7Jr/hy2FhdQnpnItkkl7F5yDtV/+RMYDKSctyiq61uLNaHvOLg/qse7m/pQdUPv1o3JaOCH507kZLOd/3r9i5DXPHBAq10fO3YUyda4gOecMUX7BrNh274ux3318yGEXpIk5hZlc7ihlaONrV3us3vtr/yRuZRk9T4z9gFfVB/aq4/LPzU2TdlDVNzoHMgswGEwMb3pKJIkiYhe0C8MKaGX334f6f6fMfKRX5F76x2kL7uUhGnTUZ1OWjZtwHmiipTzFkXUgsAfi9e6sR+MNqJvBLMl4s6KoZKxOncvLGPO6Cxe2lLJy1t6n526ZacWpc+aHHyU3aRxmqWzd38lzd6GY6qq8smBk+SnxFOalRxy7Wd5N06t7+bTn6zS6uPPmzYu5DWmFWRw6ZTRfHG4js+Pt/R6bqd1M7i19O27dyKZzVhDjApcU1HPgYyRZB8/iMfhICvJysjUBFFiKYgpQ0roLaMLkRYtZcQPfsjoR39LyT9eYeLH65m29xCz6tuYqlRS+uqbUV/fPLoQjMboI/rGBkgOLY7dCScZC1pU/9xVZ5FgNnLbv77oEUXreDyqL6I/oxehj8vS+t3EtzbzyrZKAHadbKK6xc65JXlh5TmCbZyqr67Dg8SFs8eHvAbAA0unIEnw9Pbe+9zrIwkHc3es6vHQvmc31lIZydR7J/AP91axJ7sQg8Ph8/WnFqRz3NZOdXP7QCxXMAwYUkLfG5LJhLlgZNgDPwJhiIvDUlgUlUevqqpWCRJhaSV0jtoL1gbBn9LsFH7zzVk0tju46eX1Acv0PquoRrJpNlJ8dnbQa+kdLFM7Wnj2C+01f7xPb0scuH6+OzNHZRBnNHQRepfbg72hgXazlVmjs8K6TtmIdC6fWsSeBjv/2n446HlxIwY/Ges4fAhPa2tI28budPPZwWpsxdp5bd6WxdN9Pr2wbwSxYdgIfaywjC3WxsP1khgNhOPYUa1j46jC0Cd3o9O6Ce85v3tmKRdOKGDNvhM8+fmeHve/9GUFKXbNAtH7zgdC72BZEudmfWUNSnUTHx/QhH5hCH9eJz7OxMyRGWw5Vk+bQ5um9FlFNfEdbahJKRFVPz10wVSMEvz03a0BN2EBGMxmTNk5gyr04VbcfF5Rjd3lJu/MOUDnDNmp+dq/ifDpBbFCCH2ERFtiaVd2azeKepYyhiKcZKw/kiTxl8vnkpVo4e53trDrRGeTLIfLzb+2HyLbpdkCxgBjBH3Pm5YGksQYg+bPP7NpP58eOElheiJjMsO3oOYWZePyqGz29ph/c8cREh3txKdHNhS8NDuFbxans7fGxrObg7//5vwCnMePhb3JKtaE6nGjo7c9mLnwLCSzmdatWkQ/zdvbf6uovBHECCH0EWIpjq7Esn2PJvRSYVHEzxmqBUIg8lLi+fPyM7G73Fz34ue+CVQf7K2ivs3BKKkDQ1JSr1aWZDRiTEsjzdFGeryZJ9Yp1Lc5QpZVdqfTp6/Wes9/dZgkRzvJWT2HkofiO2VZWE1GHv5gO+3OwPNWzQUFeNracDcOThfIztLKEEK/rwqz0cACeSTxZVNo37Edj8NBUXoSKdY4Yd0IYoYQ+gix+mrp94U4syv2PV4LpTDyiN6QmAiSFLLqpjsXTx7NjWcUs+VYPQ9/oLX8felLrRon3dHms2Z6w5SegaehnqtmjMHu/bAI15/X0UcLrq+sYdvxBqpr6jGqHuJSI4voAbIT4rhj/niONbXxx3WBB4nHjRjcASTtu3chWa1YxowNek5ti50tx+qZV5RNoiWOxGkzUB0O2nftwGDQyiyVapvP7hII+oIQ+gjRSyw7IiyxbN+zCwwGGDU64uf0TZmKMC8A8Niy2YzJSOJXH+3kA+U4b+08QnFmMkZboy/Z2humdK1V8fWzO0XrvOLIIvoRKQmMyUhiQ2UNb3ijeehMMkfKXQsnkRZv5hdrdgQcbGIu0EcKDnyJperxYFd2Ez9uPJLRGPS8NftOoKqw2NuaOdG7Q1ZPyE4tyMCjqnwVoE+QQBApQugjxFI0BgwGOg6EX2Kpqirtym4sY4uRoqz6MSan4InAutFJtsb5xvNd/MzHtDncXFWWj6e1tddErI4pIxO1o4Op6VbOKc7lzMIsRqWH395ZZ25RNvVtDv60fi9pLq3xWrRCn55g4a7zJtHQ7uA3a3f2uL9zpOAglFhWHcfT3o41RCJW9+d1oU/wa1kMMFXfOCXsG0EMEEIfIQaLBfOo0RFtmnLV1OCuryd+/ISon9eYnBKxdaNz9tgc7lo4iQ6XVqnyrSLN8+8tEet7Xn1IeGMDH9yymE9vj659hD4wvLa1gwW5WgMzY2rvO2J747/mj2dESjy/+3Q3J2xd683j9E1TgzGAxJuk763iRlVVVu+rIj3ezIyRGd7zJyFZLL6ErF5iKTZOCWKBEPoosI4t1uaBtgbekNSddm/FjVUOb3NQIAwpybibg0+ZCsUDS6dw9pgclowbQbFJ89rD8ui957jr6zAZDV2GgEeC7tMDnJebAEQf0QMkmE3ct2QKbQ43j6zu2jpanzQ1KJumKrQcSG8VN/tqmznc0MrC0jzf+2kwm0kom6wlZJ1OJuamEmc0sE2UWApigBD6KPD59BUHQ5ypYfdW3MSP7/3rfG8Yk1NQnU7UjtANywJhNhlZe9tS3rtlsa9zZTitIPRzepsdGw5leWkkeydInZGu2Vd9EXqAb88poTgzmac37OVgXWf+otO6GQSPvlL7negtol/TzbbRiZ8wCdXppOPgAcwmIxNzU9le1YDbE3jPgEAQLkLoo6CzuVl49k27olXcxPchog+3301v6JuT9H76pszwI/q+Cr3RYOCB86dw7+LJJDu9Hn0UVTf+xBkNPPy1qbg8Kg+81zly0JiSgiE5eXA8+sqDGOLjtVxOED70Cv2SbkKvf+Oze39fphVk0O50s7cmNr3pTzz5OJ77fozqEpU8ww0h9FHQ2dwsvISsfY9WV20d1wehTw2/DUIoOiP6cJKx2jnBhoRHwn+fM5GHvzbN9xpMKdF79DqXTy1iWn46L22p6NLa1zxC2zQ1kKhuNxw+hHX8RKQgFpfL7eHj/ScozkzuselMDwTa93qF3tfJsu/vvauxkWMP3w+fraVx1Tt9vp7g9EIIfRTotfQdYW6aat+zG/Oo0RiTkqJ+TmNy6MZm7bt2+jZm9YYu2uFV3cRO6HXcTZrQ99W6ATAYJB75+nRUFe5btdV33FxQgKu+Dk/7wDUG6zh4AByOXm2bzUfqsNmdPWwbAKusJev1iH5qDHve1L7wLB5vTunkn57o8/UEpxdC6KNA3wgTTkTvamzEeaKqTxU3ENq6se/fx67z5rH3kq+HTNjqEX0kVTf6Y2KB/hr6at3onC/nc05xLqt2H+Ozg9pQlDjdp68aOPumbVfoHjd6WeWicT33IliKxiCZzT6rT4/ot/Qxolfdbo798QncZgu1ReNo/nQtbTt39OmagtMLIfRRYIiPJ65gZFgevT0GFTfg3++mp1/rcTg4cMPVeFpbcRw5HLLG313v9egjqbqJck5uwOf3fiuJRUQPWu7hkQu1SU0/+fcWVFXtTMgOYImlPYxmZqv3VmGQpIBN4SSjEWvJOOx796CqqjblKyOJbcfro6q2qm2x89TnCrf81yN4Dlfyztg5PDpOK4+t/vMfI76e4PRFCH2UWMcWawOg7fZez/MlYvtQcQO997s5+uC9tG39PNLOAAAAIABJREFU0teit3ndp71eKyKPvl8ieq91k9x3j15nblE2l0wezfrKGv7+n4OdIwUHMKIP1cys2e5k46EaZo3KID3BEvAcqzweT0uL7wNqakE6NS0dVNnCs6DaHC5e+rKCi/76EQUPvcbtr3/B1I/+BYDhmu+wrnAarVkjqHv5hYiH3B+sa+atHUcCtr4WnNoIoY8SS3EJqGrIEst2PRHbT9ZN4wfvcvL3j2EtlSl5WfuDDin0ukcfRnmlMTUVDIY+V9340+nRx07oAX67bBYJZiN3vV2OPVPrxxPLiL6lw8neGhv1bR09xE5VVVq+2AhJyZiDtLlYe+AELo8a0J/X0ROydm9CVt84FY5988d1CnkPvMo1/1jHqt3HmJKfzpPT0jjj6E6Sz17AT267ggSLidcnnYenrY3aF54N52X7WPH3T7nkb2u54OnVHGkIbw+J4NSg9/E3gqD4mpsdPNDrV3W7r7Syj0IfYMqU8+QJKm6+CclsZuyzL5AwZRqmrGya132KqqpBe7276usxpqaGnH4EIBkMmNLSYyv0NhuGxMSwnj8SRqcn8uDSqdz1zpc8daCNS4lNG4T9tTaeWKfw7BcHaO7QWjYbDRJZiRayE61kJ1mQm6q44chh9k2fz+urtqKiib/2f/CoKhu9Q9IXj8sP+ly+hOyePaQuXOJrhbDteANfnxh8iPr+Whv/31v/IcUSx50LJnDVjDGMz02l8s7bqQFyvv9fWOOMnDcqheeb53LNxtepfvopcm+9o9eePDpbjtZTfrSeJIuJNftOMPXXb/OHS8/gqhljIpopIBgcwvpLk2W5DHgTeExRlCdkWR4FPA8YgSrgWkVROmRZvhq4E/AATyuKslKW5TjgWaAQcAM3KooS3k6jU5jO5ma9++Hte3YTl5sX9Zxane7WjerxcPC7N+CqrWHUr35L4lTNo04+az4Nb75OR2UF1iDdE10N9WH58zqmzMzYVt3YmmLmz3fnjgUTeL78IH89cIhLAWeUEb2qqny07wS//2wP/959FFWF/JR4Lpk8ioZ2B7UtHdS02jnS2MqOE42M3PouAP9IG897H/fsv6OTnWRhbmHwqVrx470llr6EbHitEP7nrXKcbg9PfmsOy6dqw21cjY3Uvfh3zKNGk/71iwA4vyiFtw8msW/OYsZ9+g5NH7xL2te+EfL9eOYL7ff8+avOprrFzg/f+g/Xvfg5b+44wh8vm0NWUmRzkAUDS0ihl2U5EfgDsMbv8MPAk4qivCrL8v8CN8my/HfgfuAMwAFslmX5DeAioFFRlKtlWV4K/AK4IsavY8CxhtGX3t3aiuPwIZLnn9Pn59OF3uOdMnXi8d9g+2g1qRdcSO6t/+U7L/nsBTS8+TrN6z4NLvT1dcRPLAv/udPT6ag42Ou3hEhwNzVhys7p83UCEWc08MfL5rDgD/W4DCY6Iqylb3e6+Ed5BX/4bA87vANbzhidyR3zJ/CtqYXEGXu6nQ6Xm91Ln8YhSVxx7de574w5SBJIgEGSkCQJCZAkGJ2WiNkUPIK2lowDSfIl8UemJZCRYO512tTqvVW8tfMo88fm8K0pnbZR7fN/w9PWRs493/d9e5qZk0hecjyPj57Hk7zDyT89GVLotffkICNS4rlwQgEmo4GFpXnc+NJ6/rX9MJ9X1PD05Wf2+o1DMLiEE9F3ABcCP/Y7di7wPe/tt4EfAQqwWVGUJgBZlj8HzgIWAX/3nrsaeKbPqz4FsIzRd8cGj+jt+xRQ1T4nYgEMflOmWv7zBcce+ilxeSMY89TKLuKbPH8BoPn02dfe0OM6nvZ2VLs9rBp6HVNGJqrLhaelxVfPHy2qquK2NWEpCT6UvK/MG5PDd+bK1LyYiruiMux1/eGzPfz8w6+oa+vAZJC4YloRdywYz5mFwefqAhhsTTj+s4nEM+YwqXgEM4t6P7/Xa8XHYyks8kX0kiQxvSCDNftOYLM7SLF27X7qcnv4/97cjCRpLan13wXV7ab6z3/EEB9P9vXf9p1vNEhcMb2Qxz9txzHtDGxrPqR9r0L8ODnoml7ffpgmu5PvnyVj8n7Qjc1M5qNbl/Dbtbu5/72tfHPlx3z3zFJ+/c2ZJHlbXQhOHUIKvaIoLsAly11+ERIVRdGbrlQDI4A8oMbvnB7HFUXxyLKsyrJsVhSlZyNxP3bsiL7Ot7y8POrHRkRmFrbdu4I+n/rhewDUJCRQ63dONOtTW7QZr3V7dlN31XJwu3H9+D62Hz4MhzuHZaseD6SkULfmQxoCPI9ardWZ29Tg6+h+XE88bvlkLdKI4P5yWK/Dbkd1uWhFivrfKZzHXV5g4HByBjknDvDOx+sYkRIf9FyXR+WXm6t460AjKWYjN0zM5LJxGeQmxEHtYcprgw8jB1BXvw8eD22TpyGFub7e8OSNgI3r+c/HHyGlpJJn1P5UXv14E9NyErqc+9reenaeaGJZcRqekxWUn9Saqqmff4ZaWQHfWMa2igpfszWA6fHan+4bE+ZzxdYv2PGzBzHc+aOg63l8dSUAsxPsPV7bwlQYtbSIBzYc4y8b9/HejkP89txRFKYErioKh2Dv31Pbqll3rJl75+QzMTP4v2d/M2D6EkNikQ0L9l0+0uNdKCsrw2KJ/JelvLycmTNnRvy4aNgtj6dl43qmT54ccCTf0bffoAoYt+R8UrxrinZ9qsfDfwC8bWxH/OhuRn73loDn7ltwHo3vvElZdhaW0V2Hkbft2M5OIKe4hMIA6wi0vsOlpZz84F0mjCwgcdqMiNfuj+NEFduA9JGjKInifYjk/VszvgRj1T5e3FLFP/77WwFtp4a2Di5/7lM+OtDIzJEZvPnt8xiRkhDgasE58MfHqQcm3vQddv//7Z13fFP1+sffJ0nbpHtQoAMQChz2KkNEZhkFZQgoctXrwKuiqFd/TuQiiF6v2yviFhygXkBB9t4bKrI57NVCkZamu2mT/P7IIG2TNmnSJNbzfr14kZyefM+Tb9Mn3/N8n+fzlOrd/vxd6N6DzF07EDVqwpKTGcwZ5h3fTlFoLMnJN+oxsgtL+GrxYsKCAvj0voE0CLvh/KRpk8kF2k6ZRnC79tbjaWlp3DuoF6+nXeMrZVvuiYvHsHYlnWZ9bjcL6tS1XNKuHqV/8waM6tfTrr3JwB399Pxr5e+8t+koj6y/yC8P9qNPkmudyCz22Zu/T3dIzDliymB7ZN15Ph7TnQk9Wrg8vrt407+4SklJicMFck3TK/NFUbR8qhKADPM/2yqQSsfNG7NCdav5PwvqpOZgMKA7f87uz2/k0LuXcQOm7BeFOWwS0r0H8a+86vBc2/BNRcqyzDn0roRuPJhLb0mtVNXSZqwtLdqa7kIP7T/Kr4cvVvr5maw8bp25ig2nrjCyXSM2Pj7YZSdv1OvRrl1FQHwCmvYdPWK3poIUglWbvkKz8NfWHCS7UMeUQe3LOfmiY0fJ3biesN59yzl5C4IgML5zU/L0Apm3jcOQn8+1H763a8ucPaY9qAe7Vx1qC1IpeXt4Ml+Pu4W8klKGfL6OeWmeyblYd+IyTy/aS2xoEF/e1ZOQQBWPzN/FYwt2UWJub+kJ8vftIePd//isqXxtUlNHvw4YY348BlgF7Aa6iaIYKYpiKKb4/FZgDXCn+dzhwMaam+tfBFlTLO3H6YuPH0MZFYWqvusrG3sENoxDGR5O0uy5KAIcx0HDbq3C0ZuLZJyRP7BwQ8HS/epYa7GUG01HnMXSUrBhUQ5PL9pLvjk1EmDH2av0/O9Kjl/N5dm+bVhwfx9CahBbzt+zC312NpFDhnkszVBtjpdb+hiIseEEqRTlNG+OZWr5ZLtEUkwYT/YuX3Wd+dksABpMfBJH3N35JgC+uelmhMBArn7+iSnsZ0OZ3sA3e04TqQlkdAfnWmA+0D2JFf9IQROg5O8/bOeNtQfdcpzSVS3jvtuCUhD4+YF+PNSjOXufGUan+Ci+3HWSfrNWeySn36DTcebBe0mfNoWCvbtrPIbuymW3bakNqnX0oigmi6K4CXgAeNr8eDpwvyiKW4Fo4FtJkoqAl4DVmL4Ipps3Zv8HKEVR3AY8AbxcC+/DJ6gtKZZ2Mm8MOh3FZ06hEVt5zAE0/+kXWm/aWaUELkBwuw4oIyLsO3pLVawTEsUWrF2mPLGiz/WcoFl1WBqQjI8P4pK2kOmrTQ3Sf9p/loGfreV6kY5PxvbgnRHJNW6ool29AoCI1GGeMZrKK3qVUkH7uCgOX86hVG/AaDTy7K/70BuMvDsimSCbLJ6y69fJ+vF7Ahs3IXKY42yaVg0i6JIYzaL0IkJGjqH4pETuxnXlzllxLJ0reUXc06UpmgDno7wpLePY9mQqTaJCmLrqABP+txNdDVbeWQUljPh6IzlFOr64qye9mpoytZrGhLH1yVTuTW7GngtZdPtwORtPXXF5fFuufTvbWvyoXbemRmNcmvISB9skUXjw9+pP9jLObMamYcqyqcggO+cuBBZWOKYHHqyhfX5NUNKNoqmKlJw6CXo9ag9k3FhwVs9eUCoJveVWtCuXo8tIt8oBAOhdqIq1oIrxnIKlXutZnZuqsLQU7B8GzUJC+e/WYxSWlvHZjhOEqwNY/Pc+DBbd21zOWbUSISiI8H4DPGEyYAqrqWLrWx09QKeEKPZdzOJYppaLOQWskTJIadGQ4W3LpzRaUyofmVhtQdr4zk357VI2+/qOotWCH8n8bBYRKYOtP7fkzj/Uw/UMqTYNI9nx1FBGzt7It3tPc/F6AQse6EukxrmeyboyPXd9u5lT1/J4KaUd93UtnyocHKjim/G30KNxPZ75dS9DPl/Hf27rwjN9W7u8sCrNz+fkjOkYVEGo9KWcW7qMhMlTXRrDaDSSvWghRp2OCy88i7hyvV8VkskSCG5QVYplkbWrlPvx+ZoQbs7dr7iqt67oXSmY8mSM3hq68cKKPsHkBA1XMpg5ujt6g5HPdpygSVQIWycNcdvJl1y6SNHhg4T17osyxPWG6VWhEVtRcv6cVWbZUji158I1nluShkIQeH9k13LOxKjXk2lJqfz7Q9Ve465OTRAEmF0QSki37mhXraDYvKrN0Bay4lg6yYnRdEpwPsxnS8NwDRsmDmJE20Q2nLpC75mrOJ+dX+3rjEYjTy7aw6bTmYxq34gZqZ3snicIAo/fKrLh8cHUD1Xz/NI0xn67mf2XnF+QpF3MYtp9TxGY/QeLO6dyrEESysP7uXjexfqLQwesukp527aQs/RXl15f28iO3g1UERGo6sVSbEct0hJfdaerlDtY4/RbNpc7bu0uVZMYvQcULGtD0MwRAQ1NmjKlGemktkrg2b5tGNY6gR1PDaVdnHuVygDa1aZq2MghngvbWFCLrcFopPjUCQCrFMLUVb9z4o9cHu3ZotJ7yFm1At35c8SMu8epzfbEyBD6NmvAljNXUd33DzAaufqFSdXyu32n0RuMPORmZktIUAALH+jL031acTRTS6f3lvHgj9tZeuQixaX2wzkfbT3OV7tO0Tkhmu/G90KhqHpl3KtpffY+M4xbm9Zn8aGLdP1gOTd/uILZu09RYLMvY4u2SMfTi/Yw8O2F9N/yM8XBYTz//cdEDxqM0mjk/f987lILxxzzZyH+5X8hqFRcnPIihhq2/awNZEfvJkFJSejOn8NQWv4DZekT68nQjSsEd+iEIiyMvO3+tqK3hG5q39ErAgNRxdZHZ66OfWdEMksfHkDDKnLqXSFn1XLAs/F5C9YN2eOm8E2H+CgEATLzionSBDLdzir3jzlfAlD/sSecvs7dXUz7PUsTO6Oq34Br381BX1TE7N2n0QQoGW/etHUHpULB+yO78cnYHoQHBfDdvjOMmr2Jhq8u4J65W/nl4AUKdab2htvT83huSRoNwzQsfqif0xvkceHBbHh8EEsfHsDtbRJJu5TNP+bvpNFrP/P0oj0cMVc5G41GFhw4T9u3l/DxNolJJ9YTUVJA85cn0zAxjpQHxwMQsncb72486vR71K5eAQoFDSY+Sf1HHqfkzGm/avAiO3o3UTdrjrGsDN3F8kU1RdJxFCEhBCY28oldgkpFWM9eFJ88US4ToCw7GwTBpdCJIiwMQaXyTIzew01HqiMwIZHSjHSPp8wZiorI27QBtdjaodSEO1g0byxSCKFBAbSoZ/pyfHVIB2JCyteYGIqLydu8EU2bdnZTKh0xpkNjApQKfjh0iZhx49FrtexY8Cuns/IY27EJEU7G1J3h0Z4tOTtlNDueSuW5fm2oFxLET/vPcee3m2nw6nzGfrOZKdvTCVQqWPxQPxIjXQuHKRUKhrVO4NcJ/Tn9yh1MGdSe4EAVH2+T6PDOUvp+vJrUL9Zz93dbyC4s4c0eCYzcv4qAhnHUf9T05Ria3A1FVDS3pB9h6sr97LlwrdrrlmVlkb9nN6E9bkYVHU38S1NQRkdz+a03KL16tSZT5XFkR+8mlhRL2zi9Ua+n+KSEWnR9Y8iT3Eiz3Go9VpadjTIqyinFQguCIKCMikbvAQVLb2bdAATGx2MoKvJo4xSA3K2bMBQVEZk61KPjWrCoWBbZbMg+0UtkbMcmPHZLZbmCvJ3bMBQVEZ4y0KXrRAcHkdoqnt8zrqPtbtrXkeab5K4n1GATtjoUCoEeTWJ5a3gyJyePYu8zw3g5pR2JESEsOnSBgjIDc8bfQrfGjoXfnKFxVAjTUztxdspoFj7Ql0Et49h29irrTlxmYMs4Dj4/nHG7FmMsLDQ55mBT/YSgVBLRP4XYvCwSr1/m3rnbyCu2H/6xoF2/BgwGIswhPFV0NAmTX0Wfm0v669MoLtUzL+0MKZ+sIfZf/2Pgp2uYvPw3Fh26QLq20K336SyyTLGbqJPMjcJPnybC/DdWcu4sxpISn8XnLdjm08eMvQswZd24Ep+3oIqOoezaH9WfWA1lHuwX6wwB5hRLXUa6S0Vi1aFdZYrJRtRCfB5MdyKKkBCKT0jWY5N6t2JSb/ufqdz1a032pFRKhquW8Z2bsvTIJRaq4hgRFk79tK207HUPtzatHeE5C4Ig0CUxhi6JMcwY2onDV3LYd+Awd3W6yWPXCFAquKN9Y+5o35jT1/L4o6CYHo3roTt/jkNzviSoWRL17i+/cR0xcDDXf1nAZPU1HsmKY9Ive/j2b70cXiPHuldz40s/dsIjXPx0FplzvmJsSVP2h5pqSZtEhbDxVCYbT2Vaz02ICKZb4xi6N6rHIDGOLonOh1WdRV7Ru4m9Fb2vM24sBHdORhESQt5W04as0WikLDurRg5PFR1F2fXsSkU1ruLNrBswregBSi+7lkVRFUajkZxVy1FGRBDa07EDcAdBEFC3bEXxqRMY9dXnoGvXr0MICiL0lt4uX2t420RCAlX8cOgif3TuSVzeNSbFKbx6NyoIAu3jougQ61plsisk1Qvj5iaxCIJA+hvTMZaWkjBlWqXiQ8uXZa+Mo3RrFMPctDMOq3yNej25a1ebKqPbdSCvuJQvd52k1ydr+WfL21AYDTy2dR4v9m/D8ZdGcmbKaLJfH8eaRwfyxrBOjGzXCIPRyOJDF5m8Yj/dP1zB9ULPb+LKK3o3sRRN2ebS3+gT61tHrwgIIPTmW8hdv5bSq1dRBAdjLC2t8YoegwF9bi6qyMga26TPzUWh0VRZ2etJLCmWunTPOfriY0fRXThP1Og7a/V9aMRWFO5PM/UWSHIcRinNvELRoQOE90+xhiBcIThQxaj2jZiXdpY5mmY8Bwy6fBgYUXPj/ZjCI4fJ+mkemnYdiB5bWTE9MCERdas2FGzbzNyZc0j+ZB1P/LyHnnZUSfP37qYsO4v8kXdb9fkLdGUoBIHUIUMpvv4bHXdtZqwig8hYk0ZOhCaQlJZxpJg7jRmNRtK1hey5kEWp3uCwzaQ7yCt6N1FFR5v02m2qY/1lRQ824ZvtW2uUcWPBmnnjYEPWqNdzduLDnHn4/io3Pmuz6Yg9LEVTOhd16asix1wNG1kL2Ta2WBrKWxYOjtBuNLWKCB84uMrzqmJ8Z1P2zdoGrTEKAvqNNasO/TOQPmMqGI0kvvoagoOK6IiBgzAUFRF78gAfj+5BXkkp987dRplZyTW3WMePv51l9rufAzC9OJYffjtLbGgQ01M7cnbKHSx9eABdZ84EpZILk1/AoLMv8SUIAomRIYzu0JhxHshysofs6D2AulkSJefOWG+xi6VjCEFB1UoVeAPbOL3FSbuic2NBaa6kdZRimT5jKte+/4asn+aRu261w3H0Wu86+kCbGL2n0K5aAYJAxKBUj41pD42dDVl75JpL9msSn7cwsGUc9UKC0GrCKGvXmfxdOzzaPtJfyN+zi5xlSwi9uScRqbc5PC/C/KWZu24N93Vtxt+6NGX3hWu8uiOdEV9voMFUU2/emL1bKVWq6HPPWPb8cxinJt/BlEEdrBlDmtZtqP/wY5ScOmmtUfAFsqP3AEFJLTDqdOjSL2E0GimSjqNu3tLjPVFrQkhyNxQajcnRZ7uuXGnBchegt7Oiv75kMZfffYsAs9RCxltvOFzV63O1XhE0s2CRfyj1kKMvu36dvF07COnajYDYmjcYcYYbK3rHjt5oMKDdsA5V/QZo2jqfVlmRAKWCaUM6MqZDYxqPGgUGA9oqvrD/jBiNRi5NmwJA4rQ3qtyDCOvVB0GtRrvOtMk9a0x3mkaHsvZCLsuPptOqfgRvdo1DzLpATN9+vDa6F8mNYuyOmTB5KsrISDLenEHpterTNWsD2dF7AEuj8JLTp9ClX8KQn+8XYRswFQ2F9uhJ0ZFDlJw8CbhWFWvhRtFUeUdfJB3nzKMPoggOpuUvy4gcdjv5u3aSt7mySKmhuBijTufVFb0yLAxleLjHYvTadWtAr6+VatiKBDVLQlCpKDrh2NEXHTlE2dVMIlIGub15OrGXyPz7+xJ9m0kMLWflcrfG8zdyli0hb8smIganWu90HaHQaAjr1ZuiI4fQXc4gXB3IikdSeC65IdLLI9n/3O08WHIegIghVafYqmJiiH95Knqtlow3pnvs/biC7Og9QJA1xfIUxcdN1XRqH6dW2mL5UF9fvgSoYYzeKlV8w9Hr8/I4NX4shrw8bvr4C4LbtSfuxVcA06q+Inovp1ZaCIhLQOehrBurWuVQx7f9nkIREEBQs+YUS8cd3iFpLWmVbsTnK6Jp257AxEZo167CWFbmsXF9Rd6uHZwYfTunxo8BhYKEV2c49Tpr+GaDSdWzZWw4d4nRNDcXruW4IIFR/5GJqFuIXP3682pDcbWB7Og9gNpGl/7GRqxvpA/sYY3Tm1fZqmjXdV5UFWL0RqORs49NoPjEcRpMepqYu+4GTJWF4QMHk7d1M3k7tpUbw9uplRYCExLQZ2dbBcJqilGvR7tmFQFx8QR3sC+05WnUYiv0Wi2lmfZleC358+H9Ujx2TUEQiEi9DX1ODvm7d3psXHcwGo1cfOUFDrRuxtnH/8H1JYvR5+VVeX7uxvUcH5rC8YF90K5ZRditfRCXryWkY2enrmlR8rQnW2woKSF34zqCkpqjbl69HpAiIIDE1/4NBgPpMxw3DaotZEfvAYIsuvRnTlNs1ibxpxV9SNfuCEFB1tVZjVb0MeWFza58+C7Xf/2FsF69SZzxn3Lnxr9kioNWXNWXWativRejhxtxenc3ZAv27aEsO4uIIUO9lmNuKbqzaCfZoi8sJG/HNoI7dCKggWea21iIHGpapVr0fHxN5iczufLf99GlX+Lad3M49bex7G/SAGnkUDI//diqumk0GslZuYxjA3ohDR9C3tbNRAwaQqs1m2i1aoNV1dUZ1K3bEBCfQO6GdZXqR/J3bMOQn+9SCC/y9hGEdO3G9cU/U7Dfu31nZUfvAVT16qEMD6fk9GmKpKOgVDr1Le8tFGo1od16WJ/XLOvmhrBZ7sb1XHr1FQLi4kn67qdKueRhN99CWN/+5K5fS/6+Pdbj3lSutCXA3NBcl37JrXFyVpnTKr0Qn7egbuU48yZ/+xaMJSUuyx44Q3if/ig0GnJWrvD42K6Ss2IpF1/6PwIaNKTDoRO03riduBcmo2ndltz1a7nw/D851L4lh5Lbc+TmLpy8cxQFe/cQeftI2mzZRctFywm75VaXrysIAhEpgyjLukahuVez1SZLCG+I85lXgiCQ+OrrAKS/5prevbvIjt4DCIJgiqWePU3R8WOomyWhqEFj89okzGYl406MvujoEU4/cA+CUknzefMdriTj7cTq9bmmW23vh25MKZYWvfCaUHT0CFe//hxBrSa8v+fCJNWhMatY2kohWLDG51M8F5+3oNBoCO+fQvHxo9bVsi8oPPg7px+8F4VaTfP5iwhqchOh3XqQOPU12m7fS0fpHE0++pTIYbeju3COomNHiL7zbtru/p0WP/1MSJeubl0/3EH4Rrt6FYrgYMJudf4OASC8fwrh/QagXbvabge42kJ29B4iqFkSxuJi9Nev+7wi1h7WLAOlskahE0VwMEJgIEWHDlCWdY3G73xIaPebHV+vd19Ce/ZCu3I5BQf2A94XNLMQ6GbRVPHZM0gjUtFnZ9Pkg49RhoZ60rwqUbd0XDSVu34dCo2m1mQYLDo+2lW+WdXrLmdwYuxIDAUFNP3qO0KTu1U6JzAhkfoP/YMW8xfT+cJVOp+9TNKcuQS3becRGyL6p4AglHP0xWdOU3xSIrx/So0WdJbN4EvTp3itEbnvE73rCJYNWbghMetPhHY3NYFWhkfUKL4sCAKq6BhKr1ym3n0PEDvhkWrPj3/pFU6MHMblt/5N8x8W+MzRB7ghg6C7nMGJEamUXrlMo7feI/a+BzxsXdUoQ0MJTGxUKXSjy0in6NgRIgan1trdY2TqMM5jitM3mDip2vP1+fnkbdlIWU4O+pwcyrQ56LU56LVa0zFtDsqISOL+7wVCu3aveqyCAk7edQelGekkzniT6JF3VHt9hUaDQuOZXgMWVDExhCR3pWCKUJI1AAAM4ElEQVTPLqvEtqXhTE0F7UK79SDy9hHkLFuCds1Kr4QCZUfvIYJstEh81WykKhQajWmTtIZNsAEiBg1Bd/ECTd6f6dSXRfiAQabNpyWLKDxy2JpeqfL2ZmxczYqmyrKyODFiKCVnzxD/8r9o+MTTtWFetajFVuSuX0uZVovKHPayhG3C3aiGrY7AhESCO3Qib+tm9Pn5Vd7J6AsLOTawD0WHD1Y7bs7SxUQOH0Xi1NfQtK78t2I0GDgz4e8U7k+j3v0P0fCfz7n1PtwlImUwBfv2krt5I8Qn3ojPD655ZXTCv14jZ/lSLk37FxGDUh1KMXgKOXTjIcqv6P0vdAMQ/8Jk4p97qcavb/rpV4jL1ji9ahIEwRqrv/zOmz5Lr1TVq4cQGIguw/nNWH1eHifG3E7RsSPUn/gk8S42i/YkFimEYpvCqdxajM/bEpE6DKNOR65ZT8ceRqOR809NpOjwQaJGjuamWV+QNHc+4tLVtNm6m/YHJTqfz6RrTjHiyvWE9LiZnKWLOdyjE2cfm0DJhfPlxrs09WVylv1KWN/+NPngY5832bZoCGnXr8VYVETe1s1o2nUgyI2mQsFt2xEz7m8UHTpA9i8LPWWqQ2RH7yHKrehbVG4M8VclIvU2gjt2Jvvn+RSk7QO8H7oRFAoC4uLRZTi3GWsoLubkuDso2LeXmHv+TuO33vOps1FX2JA1GgzkblhHQEJirafxRpoLw6pKs/zjy8/I+mkeId2602z298Te/xDRo0YT3j+FkM7JqJsloYqJQVCpCO/dl9brttJi/iI0rdpwbe63HOrUmvPPP0Pp1asYly7myofvoW4h0nzufBSBnutwVVNCu/VAGRFB7vo18Ns+jCUlLmXbOCJ+8lQElYr011+t9cI02dF7iIAGDVGEhRF0U1OUIa61QKvLCIJA3AuTwWgkf+d2wPuOHky59KVXLlf7B2UoLeX0/ePJ27KJyOGjaDrri1q/ra4OizO3NJwvPLDflM/vAdmD6ghJ7oaqXizaVSvs9iLI372TCy8+i6perMkxO7FfIAgCkcOG03ZnGk2/+pbA+ASufjqTg+1bYPzgbVTRMbT4eYm1SM/XCCoV4X0HUHL2DMaf5wOeSbFVN0ui3gMPU3LqJNfmfuv2eFUhO3oPIQgCSd/+wE2ffuVrU/yOqOEj0bS5kQXh7dANmIumDAZKr2Y6PMdoMHBu4sPkLF9K+ICBJH0zzy+E6ayhG/OGrDU+P6D24vMWBIWCyNRhlGZeqZRLXpqZyal7x2HU60n6Zp41jdXpsZVK6t19D+1+O0Lj9z5CERIKSiXNf1xYLhTqD1gloNP2oIyKqjLjzBXiX5yMQqMh/c0ZGIqLPTKmPWRH70EiBw91qfLur4KgUBD3/Mumx0FBPqkxCEgwV8c6KJoy6HScm/SoKQTRvQfNf1joN7UQqthYlNHR1syb3HVrTDLJXsrnt2SX2IqcGcvKOP3A3yi9nEHitNcJ7zegxuMrAgNp8OjjdDxyCuF/iwnr5XqXrNrGVgI6ImWwxxYAgXHx1H/sCUrTL3H16889MqY9ZEcv4xWiR49F064D6uYtfXL9GzIIleP0pZlXkG4byLXv5hDcsTMtf17m1Vz56hAEAY3YipIzpynLyiJ/905CuiRbZSlqm4iUQQgqlbUyGODStFfI27qZyOGjaPjM8x65jkKjQahBMZ83CGpyE+oWps9udWqVrhL3z+dRhodz+e03q9TvcQfZ0ct4BUGppPWaTbRas8kn17emWFZY0efv2cWRW7uTv3MH0WPH0WrNJr+JDduibtkKDAb++OYrjKWlXgnbWFCGhxN2ax8K96ehu3KZ7MW/mDdMW9L0s699nhXjLerdez/ExhI52LOOXhUTQ8OnnqUs6xqZs/7r0bEtyI5exmsow8OteeDexhq6sZEr/uObrzmeOoDSzCs0+vfbNJsz12830i3iZplffAq4102qJlhkmTNnfsDZiRNQBAfTfN4Cn/0+fUHc/72IYuGyWrmTavDE06jqxXLlo/fdVlm1h+zoZf4S2IZuDDod555+gnOTHkURGkrLX1fQ8Kln/Xplasm8KU2/hCI0lBAPbQY6S6S57d6V/75v6j8w60s0bdp61Ya6jDIsjCbvfUSIjfigJ/F9SoGMjBcIaBgHgkDRkcNIw1LI37UTTfuOtPhxoV/09q0OjY1+Unjf/l7PL1cnNUfdQqT4pESDx58i5s5xXr3+X4HoMXcSPebOWhlbdvQyfwkUgYGoYutbS/Sj77ybm2Z9gTI42MeWOUdg4yYIajXG4mKvxudtSXzt3+Ru2UTiG2/55PoyNUcO3cj8ZVA3bwEKBY3efIdms7//0zh5MKWoWiquvR2ftxA1fCRN3vmgUv8BGf9HXtHL/GVoNvt79FqtxyRsvU38i69QeGB/ObkNGRln8IqjF0XxA+BmwAg8LUnSXm9cV0bGlqDERuCGEJWviR41muhRo31thsyfkFoP3Yii2BdoIUlST2AC8FFtX1NGRkZG5gbeWNGnAIsBJEk6JopilCiK4ZIk5Xr6Qgv6TEK3K4vK3TUdIFj+CTeeg+m+A8BoND12pglMxcy8Kl5jtc+T1/cgTs+fj/CYfYKDx2DzO3B9WL+Zv4qfL/Ox4z7+fFWHw78P22OOsH0/1b0/R+NX83qP/36FG/8LDYK449BHaDzcs8Ebjr4hYNvy/A/zsSod/eHDh12+kKJ5JEKuE8JAtn/Ell+m5XnFP35BKPeLqDRGxXEdfQjtvdad68vUDEe/N+tjY+UvXgv+MP9VfcZsz7H8b/v5qvj6ip8v8J/3aPnfnv3VUd3784f5qfg+zM+V9TUcPnoMRYBnXbMvNmOdmqp27doR5KKoVPLsZNLS0khOTq6RYd5Ats89ZPvcQ7bPPfzZvpKSEocLZG+kV2ZgWsFbiAcue+G6MjIyMjJ4x9GvAcYCiKLYBciQJKl2JNpkZGRkZCpR645ekqQdQJooijswZdw8UdvXlJGRkZG5gVdi9JIk1bwjtYyMjIyMW8gSCDIyMjJ1HNnRy8jIyNRxZEcvIyMjU8fxR1EzJYBOp6vxACUlJR4zpjaQ7XMP2T73kO1zD3+1z8ZnKiv+TDAa/av+OS0t7VZgq6/tkJGRkfmT0js5OXmb7QF/XNHvBXpjKqrS+9gWGRkZmT8LSiAOkw8th9+t6GVkZGRkPIu8GSsjIyNTx5EdvYyMjEwdR3b0MjIyMnUc2dHLyMjI1HFkRy8jIyNTx/HH9Moa4e8NyEVR7AcsAI6YDx2SJOlJ31lkQhTFdsCvwAeSJH0simIj4HtMqVqXgfskSfJZhYgd+74BkoEs8ynvSJK03If2vY0pHVgFvIkptc2f5q+ifSPwk/kTRTEY+AZoAKiBGcAB/GT+HNg3Fj+ZP1eoE47etgG5KIqtgdlATx+bZY/NkiSN9bURFkRRDAFmAuttDr8GzJIkaYEoiv8GHgI+9SP7AF6WJGmZD0wqhyiK/YF25s9dDLAfk63+Mn/27NuAn8wfMBzYJ0nS26IoNgHWAtvxk/lzYN8O/Gf+nKauhG7KNSAHokRR9Gx33bpJCTAMUxcwC/2AJebHS4GBXrbJFnv2+RNbgDvNj3OAEPxr/uzZV6k83ldIkvQ/SZLeNj9tBFzCj+bPgX1/SurEip4aNiD3AW1EUVwCRAPTJUla60tjJEkqA8pEUbQ9HGJzq3wVU6WdT3BgH8AkURSfxWTfJEmSrnndOECSJD1QYH46AVgBDPGj+bNnnx4/mT8L5qZEicDtwDp/mT8LFex7Fj+bP2eoKyv6ivhDL/uKnASmAyOB+4GvRVEM9K1J1eKP8/g98JIkSQOA34FpvjUHRFEcicmRTqrwI7+Yvwr2+d38SZJ0C6a9g7mUnzO/mL8K9vnd/DlDXXH0ft+AXJKkdPOtoFGSpNPAFSDB13bZIV8URY35cQJ+FjaRJGm9JEm/m58uAdr70h5RFIcArwBDJUnS4mfzV9E+f5o/URSTzZv/mG1SAXn+Mn8O7DvkL/PnCnXF0ft9A3JRFO8RRfE58+OGmHby031rlV3WAWPMj8cAq3xoSyVEUfxZFMVm5qf9gMM+tCUCeAe4XZKkbPNhv5k/e/b50/wBfYD/AxBFsQEQih/NH/bt+9yP5s9p6oyomSiK/8H0izEAT0iSdMDHJpVDFMUw4AcgEgjEFKNf4WObkoH3gJuAUkxfPPdgSilTA+eBByVJKvUj+2YCLwGFQL7Zvqs+su8RTLfuJ2wO3w98hX/Mnz375mAK4fjD/GmArzFtdGowhTb3Ad/hH/Nnz7584G38YP5coc44ehkZGRkZ+9SV0I2MjIyMjANkRy8jIyNTx5EdvYyMjEwdR3b0MjIyMnUc2dHLyMjI1HFkRy8jIyNTx5EdvYyMjEwd5/8BmjjNU6KEJxcAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"loss : \", loss)\n",
        "print(\"accuracy : \", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LaDV0JNZLVg",
        "outputId": "067ca662-5f07-47ff-cf9d-02eecc4d2b2b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss :  98.56060791015625\n",
            "accuracy :  0.6470000147819519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test) > 0.5\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05KZQ2qgZN2b",
        "outputId": "04cecc00-901f-45de-d3ec-c7d02fffeb81"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1177  416]\n",
            " [ 290  117]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.74      0.77      1593\n",
            "           1       0.22      0.29      0.25       407\n",
            "\n",
            "    accuracy                           0.65      2000\n",
            "   macro avg       0.51      0.51      0.51      2000\n",
            "weighted avg       0.68      0.65      0.66      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtClIKhNPtU3"
      },
      "source": [
        "#### Monitor the \"val_loss\" as metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXp9EPdUPtU4"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8DV-OiWPtU4"
      },
      "source": [
        "#### Monitor the \"val_recall\" as metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTOuhaJjPtU4"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WoGGKHgPtU4"
      },
      "source": [
        "## GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "XvXABFQVPtU5"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model = LogisticRegression()\n",
        "\n",
        "penalty = [\"l1\", \"l2\"]\n",
        "C = np.logspace(-1, 5, 20)\n",
        "class_weight= [\"balanced\", None] \n",
        "solver = [\"lbfgs\", \"liblinear\", \"sag\", \"saga\"]\n",
        "\n",
        "param_grid = {\"penalty\" : penalty,\n",
        "              \"C\" : [C,1],\n",
        "              \"class_weight\":class_weight,\n",
        "              \"solver\":solver}\n",
        "\n",
        "\n",
        "grid_model = GridSearchCV(estimator=model,\n",
        "                          param_grid=param_grid,\n",
        "                          cv=10,\n",
        "                          scoring = 'accuracy',       \n",
        "                          n_jobs = -1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_model.fit(X_train_scaled,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVpwsrofV50y",
        "outputId": "09c6c8b3-09db-4bd6-c089-d03b6a23e661"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10, estimator=LogisticRegression(), n_jobs=-1,\n",
              "             param_grid={'C': [array([1.00000000e-01, 2.06913808e-01, 4.28133240e-01, 8.85866790e-01,\n",
              "       1.83298071e+00, 3.79269019e+00, 7.84759970e+00, 1.62377674e+01,\n",
              "       3.35981829e+01, 6.95192796e+01, 1.43844989e+02, 2.97635144e+02,\n",
              "       6.15848211e+02, 1.27427499e+03, 2.63665090e+03, 5.45559478e+03,\n",
              "       1.12883789e+04, 2.33572147e+04, 4.83293024e+04, 1.00000000e+05]),\n",
              "                               1],\n",
              "                         'class_weight': ['balanced', None],\n",
              "                         'penalty': ['l1', 'l2'],\n",
              "                         'solver': ['lbfgs', 'liblinear', 'sag', 'saga']},\n",
              "             scoring='accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_model.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2CbkK6wV9DL",
        "outputId": "e98f4e99-a377-45b7-fede-9c827ccf7322"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 1, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear'}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_metric(grid_model, X_train_scaled, y_train, X_test_scaled, y_test)  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDNFZFUHWAdz",
        "outputId": "7bbf05b7-954e-4368-c755-d6b5a49573e2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test_Set\n",
            "[[1535   58]\n",
            " [ 323   84]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.96      0.89      1593\n",
            "           1       0.59      0.21      0.31       407\n",
            "\n",
            "    accuracy                           0.81      2000\n",
            "   macro avg       0.71      0.58      0.60      2000\n",
            "weighted avg       0.78      0.81      0.77      2000\n",
            "\n",
            "\n",
            "Train_Set\n",
            "[[6164  206]\n",
            " [1301  329]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.97      0.89      6370\n",
            "           1       0.61      0.20      0.30      1630\n",
            "\n",
            "    accuracy                           0.81      8000\n",
            "   macro avg       0.72      0.58      0.60      8000\n",
            "weighted avg       0.78      0.81      0.77      8000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPadg2bCPtU5"
      },
      "source": [
        "### Evaluate The Model\n",
        "\n",
        "- Plot the model history to observe the changing of metrics\n",
        "- Make prediction to see \"confusion matrix\" and \"classification report\"\n",
        "- Check ROC (Receiver Operating Curve) and AUC (Area Under Curve) for the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "A8RnRtKJPtU6",
        "outputId": "7c87d906-4566-4265-ab50-e3419b38c56d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "y_pred_proba = model.predict(X_test)\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "plt.plot([0,1],[0,1],'k--')\n",
        "plt.plot(fpr,tpr, label='ANN')\n",
        "plt.xlabel('fpr')\n",
        "plt.ylabel('tpr')\n",
        "plt.title('ROC curve')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "roc_auc_score(y_test, y_pred_proba)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SG4-RuMaMHA",
        "outputId": "dbefe499-6874-4b7d-d7bc-3a00a5ea1658"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.537940868449343"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8qtkfxQPtU6"
      },
      "source": [
        "# Final Model and Model Deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2K_Kg8P4PtU6"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq10ovAX6daY"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xIrc0TZPtU7"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLHTpRI-PtU7"
      },
      "source": [
        "___\n",
        "\n",
        "<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" alt=\"CLRSWY\"></p>\n",
        "\n",
        "___"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DL-Assignment-1 (Classification with ANN-Churn Prediction)-Student.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "d84a699600f653cbb48bf7dbc447296f7ff0e2382f33cf7ad949179950974029"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}